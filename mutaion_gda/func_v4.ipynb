{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlgda_solver\u001b[39m(\n\u001b[1;32m----> 2\u001b[0m     x0: np\u001b[38;5;241m.\u001b[39mndarray, y0: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m      3\u001b[0m     D: \u001b[38;5;28mint\u001b[39m, J: \u001b[38;5;28mint\u001b[39m, num_rows_columns: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m      4\u001b[0m     p: \u001b[38;5;28mint\u001b[39m, r: \u001b[38;5;28mint\u001b[39m, \n\u001b[0;32m      5\u001b[0m     alpha: \u001b[38;5;28mfloat\u001b[39m, beta: \u001b[38;5;28mfloat\u001b[39m, \n\u001b[0;32m      6\u001b[0m     h: np\u001b[38;5;241m.\u001b[39mndarray, J_L: \u001b[38;5;28mset\u001b[39m, J_F: \u001b[38;5;28mset\u001b[39m,\n\u001b[0;32m      7\u001b[0m     eta_x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m, eta_y: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m      8\u001b[0m     mu: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m      9\u001b[0m     max_iter: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, tau_interval: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     10\u001b[0m     tol: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m,\n\u001b[0;32m     11\u001b[0m     return_history: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ):\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"LGDA with Mutation (Algorithm 4) solver (final one-shot projection).\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     demand_points, candidate_sites \u001b[38;5;241m=\u001b[39m generate_instance(num_rows_columns, D, J, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def lgda_solver(\n",
    "    D: int, J: int, num_rows_columns: int,\n",
    "    p: int, r: int,\n",
    "    alpha: float, beta: float,\n",
    "    h: np.ndarray, J_L: set, J_F: set,\n",
    "    *,  # ここから下はキーワード専用\n",
    "    eta_x: float = 0.01, eta_y: float = 0.01,\n",
    "    mu: float = 0.01,\n",
    "    max_iter: int = 500, tau_interval: int = 10,  # ← N = tau_interval\n",
    "    tol: float = 1e-6,\n",
    "    enforce_no_overlap: bool = False,\n",
    "    return_history: bool = False,\n",
    "    fix_seed: bool = False,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"LGDA with Mutation. 各反復では連続緩和に射影、終了時に 0/1 射影。\n",
    "    基準戦略 cp,cq は t が N,2N,3N,... のときに p(t),q(t) へ更新。\n",
    "    \"\"\"\n",
    "    if fix_seed is True:\n",
    "        seed_int = seed\n",
    "    else:\n",
    "        rng = np.random.default_rng()\n",
    "        seed_int = int(rng.integers(0, 2**32, dtype=np.uint64))  # 上端は排他的\n",
    "    print(seed_int)\n",
    "    # インスタンス生成\n",
    "    demand_points, candidate_sites = generate_instance(num_rows_columns, D, J, seed=seed_int)\n",
    "    distances = compute_distances(demand_points, candidate_sites)\n",
    "    w = compute_wij_matrix(distances, alpha, beta)\n",
    "    Ui_L = compute_Ui_L(w, J_L)\n",
    "    Ui_F = compute_Ui_F(w, J_F)\n",
    "    \n",
    "    x0 = np.random.rand(len(candidate_sites))  # 例: 初期値\n",
    "    y0 = np.random.rand(len(candidate_sites))  # 同じ次元\n",
    "\n",
    "    # 初期化（可行域へ）\n",
    "    x = project_box_l1(np.clip(x0, 0, 1), p)\n",
    "    #y = project_box_l1(np.clip(y0, 0, 1), r, mask=(x > 0) if enforce_no_overlap else None)\n",
    "    y = project_box_l1(np.clip(y0, 0, 1), r)\n",
    "\n",
    "    # 基準戦略（時刻0の戦略で初期化）\n",
    "    cp, cq = x.copy(), y.copy()\n",
    "\n",
    "    obj_vals, dx_vals, dy_vals = [], [], []\n",
    "    prev_obj = None\n",
    "\n",
    "    # 反復：t = 1..max_iter\n",
    "    for t in range(1, max_iter + 1):\n",
    "        gx = grad_x(x, y, w, Ui_L, Ui_F, h)  # ∇_x L（上昇方向に用いる）\n",
    "        gy = grad_y(x, y, w, Ui_L, Ui_F, h)  # ∇_y L（下降方向に用いる）\n",
    "\n",
    "        # Mutation 付き更新：x 上昇, y 下降 + 参照点への引き戻し\n",
    "        x_tmp = x + eta_x * (gx - mu * (x -cp))\n",
    "        y_tmp = y + eta_y * (-gy - mu * (y -cq))\n",
    "\n",
    "        # 連続緩和の集合へ射影\n",
    "        x_next = project_box_l1(x_tmp, p)\n",
    "        y_next = project_box_l1(y_tmp, r)\n",
    "\n",
    "        dx = np.linalg.norm(x_next - x)\n",
    "        dy = np.linalg.norm(y_next - y)\n",
    "\n",
    "        new_obj = compute_Lhat(x_next, y_next, w, Ui_L, Ui_F, h)\n",
    "        obj_vals.append(new_obj)\n",
    "        dx_vals.append(dx)\n",
    "        dy_vals.append(dy)\n",
    "\n",
    "        # 状態更新\n",
    "        x, y = x_next, y_next\n",
    "\n",
    "        # 収束判定（必要なら有効化）\n",
    "        \"\"\"\n",
    "        if (max(dx, dy) < tol) or (prev_obj is not None and abs(new_obj - prev_obj) < tol):\n",
    "            prev_obj = new_obj\n",
    "            # t が N の倍数なら、仕様通り cp,cq を p(t),q(t) に更新してから抜ける\n",
    "            if (t % tau_interval) == 0:\n",
    "                cp, cq = x.copy(), y.copy()\n",
    "            break\n",
    "        \"\"\"\n",
    "        prev_obj = new_obj\n",
    "\n",
    "        # 時刻 N ごとに cp,cq を今日の戦略 p(t), q(t) に更新\n",
    "        if (t % tau_interval) == 0:\n",
    "            cp, cq = x.copy(), y.copy()\n",
    "            # print(\"copy\")\n",
    "\n",
    "    # 終了時に 0/1 射影で確定解\n",
    "    x_proj = project_cardinality(x, p)\n",
    "    # y_proj = project_cardinality(y, r, mask=(x_proj > 0) if enforce_no_overlap else None)\n",
    "    y_proj = project_cardinality(y, r)\n",
    "\n",
    "    obj_final_relaxed = compute_Lhat(x, y, w, Ui_L, Ui_F, h)          # 連続版\n",
    "    obj_final_binary  = compute_Lhat(x_proj, y_proj, w, Ui_L, Ui_F, h) # 0/1版\n",
    "    obj_final_ex      = compute_L(h, Ui_L, Ui_F, w, x_proj, y_proj)    # 別定義がある場合\n",
    "\n",
    "    history = {\"objective\": np.array(obj_vals), \"dx\": np.array(dx_vals), \"dy\": np.array(dy_vals)}\n",
    "\n",
    "    if return_history:\n",
    "        return x, y, obj_final_relaxed, x_proj, y_proj, obj_final_binary, obj_final_ex, candidate_sites, demand_points, history\n",
    "    return x, y, obj_final_relaxed, x_proj, y_proj, obj_final_binary, obj_final_ex, candidate_sites, demand_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instance(num_rows_columns, I, J, seed=42):\n",
    "    \"\"\"\n",
    "    Generate I demand points and J candidate facility sites from a grid of size num_rows_columns x num_rows_columns.\n",
    "    Returns: (demand_points, candidate_sites)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # すべての格子点を生成（1始まり）\n",
    "    all_points = [(x, y) for x in range(1, num_rows_columns + 1)\n",
    "                         for y in range(1, num_rows_columns + 1)]\n",
    "    \n",
    "    # ランダムにシャッフル\n",
    "    random.shuffle(all_points)\n",
    "    \n",
    "    # 十分な点があるか確認\n",
    "    assert I + J <= len(all_points), \"Grid is too small for given I and J.\"\n",
    "    \n",
    "    demand_points = all_points[:I]\n",
    "    candidate_sites = all_points[I:I+J]\n",
    "    \n",
    "    return demand_points, candidate_sites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Ui_L(wij_matrix, J_L):\n",
    "    \"\"\"\n",
    "    リーダーの既存施設による U_i^L を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "        wij_matrix (np.array): D × J の w_ij の重み行列\n",
    "        J_L (set): リーダーが既に持っている施設のインデックス集合\n",
    "\n",
    "    Returns:\n",
    "        np.array: 各需要点 i に対する U_i^L のベクトル\n",
    "    \"\"\"\n",
    "    D, _ = wij_matrix.shape  # D: 需要点の数, J: 候補施設の数\n",
    "\n",
    "    # J_L が空なら影響はゼロ\n",
    "    if not J_L:\n",
    "        return np.zeros(D)\n",
    "\n",
    "    # 各需要点 i に対して、リーダーの施設 j ∈ J_L からの重みを合計する\n",
    "    utility_vector = np.zeros(D)\n",
    "    for j in J_L:\n",
    "        # 列 j は、施設 j が各需要点に与える重み\n",
    "        utility_vector += wij_matrix[:, j]\n",
    "\n",
    "    return utility_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Ui_F(wij_matrix, J_F):\n",
    "    \"\"\"\n",
    "    リーダーの既存施設による U_i^L を計算する関数\n",
    "\n",
    "    Parameters:\n",
    "        wij_matrix (np.array): D × J の w_ij の重み行列\n",
    "        J_L (set): リーダーが既に持っている施設のインデックス集合\n",
    "\n",
    "    Returns:\n",
    "        np.array: 各需要点 i に対する U_i^L のベクトル\n",
    "    \"\"\"\n",
    "    D, _ = wij_matrix.shape  # D: 需要点の数, J: 候補施設の数\n",
    "\n",
    "    # J_L が空なら影響はゼロ\n",
    "    if not J_F:\n",
    "        return np.zeros(D)\n",
    "\n",
    "    # 各需要点 i に対して、リーダーの施設 j ∈ J_L からの重みを合計する\n",
    "    utility_vector = np.zeros(D)\n",
    "    for j in J_F:\n",
    "        # 列 j は、施設 j が各需要点に与える重み\n",
    "        utility_vector += wij_matrix[:, j]\n",
    "\n",
    "    return utility_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wij_matrix(distances, alpha=0, beta=0.1):\n",
    "    wij_matrix = np.exp(alpha - beta * distances)\n",
    "    return wij_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(demand_points, candidate_sites):\n",
    "    D, J = len(demand_points), len(candidate_sites)  # ここで D, J を定義\n",
    "    distances = np.zeros((D, J))\n",
    "    for d in range(D):\n",
    "        for j in range(J):\n",
    "            distances[d, j] = np.sqrt(\n",
    "                (demand_points[d][0] - candidate_sites[j][0]) ** 2\n",
    "                + (demand_points[d][1] - candidate_sites[j][1]) ** 2\n",
    "            )\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_x(x: np.ndarray, y: np.ndarray, w: np.ndarray,\n",
    "           Ui_L: np.ndarray, Ui_F: np.ndarray, h: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Gradient of \\hat{L} with respect to x (ascent direction).\"\"\"\n",
    "    Ai = compute_Ai(x, y, w, Ui_L)\n",
    "    Bi = compute_Bi(x, y, w, Ui_L, Ui_F)\n",
    "\n",
    "    dA_dx = w * ((1.0 + y) - 2.0 * y * x)     # shape (I, J)\n",
    "    dB_dx = w * (1.0 - y)\n",
    "\n",
    "    frac = (Bi[:, None] * dA_dx - Ai[:, None] * dB_dx) / (Bi[:, None] ** 2) + 1e-8\n",
    "    return (frac * h[:, None]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_y(x: np.ndarray, y: np.ndarray, w: np.ndarray,\n",
    "           Ui_L: np.ndarray, Ui_F: np.ndarray, h: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Gradient of \\hat{L} with respect to y (descent direction).\"\"\"\n",
    "    Ai = compute_Ai(x, y, w, Ui_L)\n",
    "    Bi = compute_Bi(x, y, w, Ui_L, Ui_F)\n",
    "\n",
    "    dA_dy = w * (-x ** 2 + x)\n",
    "    dB_dy = w * (1.0 - x)\n",
    "\n",
    "    frac = (Bi[:, None] * dA_dy - Ai[:, None] * dB_dy) / (Bi[:, None] ** 2) + 1e-8\n",
    "    return (frac * h[:, None]).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Lhat(x: np.ndarray, y: np.ndarray, w: np.ndarray,\n",
    "                 Ui_L: np.ndarray, Ui_F: np.ndarray, h: np.ndarray) -> float:\n",
    "    \"\"\"Evaluate the objective \\hat{L}(x, y).\"\"\"\n",
    "    Ai = compute_Ai(x, y, w, Ui_L)\n",
    "    Bi = compute_Bi(x, y, w, Ui_L, Ui_F)\n",
    "    return float(np.dot(h, Ai / Bi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_cardinality(v: np.ndarray, k: int, mask: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"Project a vector onto the set {0,1}^J with at most *k* ones.\"\"\"\n",
    "    v = np.clip(v, 0.0, 1.0)\n",
    "    if mask is not None:\n",
    "        v = v * (~mask)\n",
    "\n",
    "    if k >= v.size:\n",
    "        return (v > 0).astype(float)\n",
    "\n",
    "    idx = np.argpartition(-v, k)[:k]\n",
    "    out = np.zeros_like(v)\n",
    "    out[idx] = 1.0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_box_l1(v: np.ndarray, k: int, mask: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Project v onto { z in [0,1]^n : sum(z) <= k }.\n",
    "    If mask is given (bool array), force z[mask]=0 before projection.\n",
    "\n",
    "    project_cardinality関数との違いだが、こちらは連続値で [0,1] の範囲にクリップしてから、合計が k 以下になるように調整する。\n",
    "    \"\"\"\n",
    "    z = v.copy()\n",
    "\n",
    "    # 0 固定マスク\n",
    "    if mask is not None:\n",
    "        z = z.copy()\n",
    "        z[mask] = 0.0\n",
    "\n",
    "    # まず [0,1] にクリップ\n",
    "    z = np.clip(z, 0.0, 1.0)\n",
    "\n",
    "    s = z.sum()\n",
    "    if s <= k:\n",
    "        return z  # 既に可行\n",
    "\n",
    "    # 合計が大きい場合：tau を探して z = clip(v - tau, 0, 1) の合計を k にする\n",
    "    # 単峰・区分線形なので 2 分探索で十分安定\n",
    "    lo, hi = -1.0, 1.0\n",
    "    # 範囲を拡張してカバー\n",
    "    vmax = np.max(v)\n",
    "    vmin = np.min(v)\n",
    "    lo = vmin - 1.0\n",
    "    hi = vmax\n",
    "\n",
    "    def S(tau):\n",
    "        return np.clip(v - tau, 0.0, 1.0).sum()\n",
    "\n",
    "    for _ in range(60):  # 1e-18 くらいまで収束\n",
    "        mid = (lo + hi) / 2.0\n",
    "        if S(mid) > k:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    z = np.clip(v - hi, 0.0, 1.0)\n",
    "\n",
    "    if mask is not None:\n",
    "        z[mask] = 0.0\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Ai(x: np.ndarray, y: np.ndarray, w: np.ndarray, Ui_L: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute A_i = U_i^L + Σ_j w_ij[-y_j x_j^2 + (1+y_j)x_j] for all i.\"\"\"\n",
    "    term = w * ((1.0 + y) * x - y * x ** 2)  # broadcast over j\n",
    "    Ai = Ui_L + term.sum(axis=1)\n",
    "    # print(\"Ai min:\", np.min(Ai))\n",
    "    return Ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Bi(x: np.ndarray, y: np.ndarray, w: np.ndarray,\n",
    "               Ui_L: np.ndarray, Ui_F: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute B_i = U_i^L + U_i^F + Σ_j w_ij[(1-y_j)x_j + y_j] for all i.\"\"\"\n",
    "    term = w * ((1.0 - y) * x + y)\n",
    "    Bi = Ui_L + Ui_F + term.sum(axis=1)\n",
    "    # print(\"Bi min:\", np.min(Bi))\n",
    "    return Bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_minmax_history(L_vals: list | np.ndarray,\n",
    "                        dx_vals: list | np.ndarray,\n",
    "                        dy_vals: list | np.ndarray,\n",
    "                        *, logy: bool = True):\n",
    "    \"\"\"Plot convergence history returned by *minmax_solver*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    L_vals : sequence of float\n",
    "        Objective values (hist_Lcont).\n",
    "    dx_vals : sequence of float\n",
    "        Norm of x updates.\n",
    "    dy_vals : sequence of float\n",
    "        Norm of y updates.\n",
    "    logy : bool, default True\n",
    "        Use log scale for dx/dy curves.\n",
    "    \"\"\"\n",
    "    L_vals = np.asarray(L_vals)\n",
    "    dx_vals = np.asarray(dx_vals)\n",
    "    dy_vals = np.asarray(dy_vals)\n",
    "    iters = np.arange(1, len(L_vals) + 1)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.plot(iters, L_vals, label=\"objective\", linewidth=1.5, color=\"tab:blue\")\n",
    "    ax1.set_xlabel(\"iteration\")\n",
    "    ax1.set_ylabel(\"objective\")\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(iters, dx_vals, linestyle=\"--\", label=\"‖Δx‖\", color=\"tab:orange\")\n",
    "    ax2.plot(iters, dy_vals, linestyle=\":\", label=\"‖Δy‖\", color=\"tab:green\")\n",
    "    ax2.set_ylabel(\"step size\")\n",
    "    if logy:\n",
    "        ax2.set_yscale(\"log\")\n",
    "\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    l2, lab2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines + l2, labels + lab2, loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_facility_selection(candidate_sites, demand_points, x_bin, y_bin):\n",
    "    \"\"\"\n",
    "    施設配置の可視化関数。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    candidate_sites : list of tuple(float, float)\n",
    "        候補施設の座標 [(x1, y1), (x2, y2), ...]\n",
    "    demand_points : list of tuple(float, float)\n",
    "        需要点の座標 [(x1, y1), (x2, y2), ...]\n",
    "    x_bin : array-like of 0/1\n",
    "        リーダーによって選ばれた施設（青丸で表示）\n",
    "    y_bin : array-like of 0/1\n",
    "        フォロワーによって選ばれた施設（赤丸で表示）\n",
    "    \"\"\"\n",
    "    # 座標分解\n",
    "    candidate_x = [pt[0] for pt in candidate_sites]\n",
    "    candidate_y = [pt[1] for pt in candidate_sites]\n",
    "    demand_x = [pt[0] for pt in demand_points]\n",
    "    demand_y = [pt[1] for pt in demand_points]\n",
    "\n",
    "    # プロット開始\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    # 需要点（黒）\n",
    "    plt.scatter(demand_x, demand_y, color='black', marker='x', label='Demand Points')\n",
    "\n",
    "    # 候補地（グレー）\n",
    "    plt.scatter(candidate_x, candidate_y, color='gray', label='Candidate Sites')\n",
    "\n",
    "    # x_bin == 1 → 青い○（枠のみ）\n",
    "    for i, val in enumerate(x_bin):\n",
    "        if val == 1:\n",
    "            plt.scatter(candidate_sites[i][0], candidate_sites[i][1],\n",
    "                        s=200, facecolors='none', edgecolors='blue', linewidths=2,\n",
    "                        label='x_bin = 1' if 'x_bin = 1' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "    # y_bin == 1 → 赤い●\n",
    "    for i, val in enumerate(y_bin):\n",
    "        if val == 1:\n",
    "            plt.scatter(candidate_sites[i][0], candidate_sites[i][1],\n",
    "                        s=100, color='red',\n",
    "                        label='y_bin = 1' if 'y_bin = 1' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "    # 軸・凡例など\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Demand Points and Candidate Sites with Selections')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_each_history_component_separately(\n",
    "    history,\n",
    "    *,\n",
    "    logy: bool = True,\n",
    "    fix_seed: bool = False,\n",
    "    save: bool = False,\n",
    "    save_prefix: str = \"history\",\n",
    "    save_ext: str = \"png\",\n",
    "    dpi: int = 300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot objective, ‖dx‖, and ‖dy‖ from the LGDA solver history as separate figures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : dict with keys \"objective\", \"dx\", \"dy\"\n",
    "        Output from lgda_solver with return_history=True.\n",
    "    logy : bool\n",
    "        Whether to use logarithmic scale for ‖dx‖ and ‖dy‖ plots.\n",
    "    \"\"\"\n",
    "    iters = np.arange(1, len(history[\"objective\"]) + 1)\n",
    "\n",
    "    # 1. Objective\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(iters, history[\"objective\"], label=\"Objective\", color=\"tab:blue\", linewidth=1.5)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective Value\")\n",
    "    # plt.title(\"Objective over Iterations\")\n",
    "    plt.grid(True)\n",
    "    # plt.legend()\n",
    "    if fix_seed is True:\n",
    "        plt.ylim(0.5,0.545)\n",
    "        # pass\n",
    "\n",
    "    if save:\n",
    "        fname = f\"{save_prefix}_objective.{save_ext}\"\n",
    "        plt.savefig(fname, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(\"save pic:\", fname)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. dx\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(iters, history[\"dx\"], label=\"‖Δx‖\", color=\"tab:orange\", linestyle=\"--\", linewidth=1.5)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"‖Δx‖\")\n",
    "    # plt.title(\"‖dx‖ over Iterations\")        \n",
    "    # plt.ylim(bottom=-1) \n",
    "    plt.grid(True)\n",
    "    # plt.legend()\n",
    "\n",
    "    if save:\n",
    "        fname = f\"{save_prefix}_dx.{save_ext}\"\n",
    "        plt.savefig(fname, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(\"save pic:\", fname)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. dy\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(iters, history[\"dy\"], label=\"‖Δy‖\", color=\"tab:green\", linestyle=\":\", linewidth=1.5)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"‖Δy‖\")\n",
    "    # plt.title(\"‖dy‖ over Iterations\")\n",
    "    #plt.ylim(bottom=-1) \n",
    "    plt.grid(True)\n",
    "    # plt.legend()\n",
    "\n",
    "    if save:\n",
    "        fname = f\"{save_prefix}_dy.{save_ext}\"\n",
    "        plt.savefig(fname, dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(\"save pic:\", fname)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L(h_i, Ui_L, Ui_F, wij, x, y):\n",
    "    \"\"\"\n",
    "    関数 L(x, y) を計算する\n",
    "\n",
    "    Parameters:\n",
    "        h (np.array): 需要点ごとの人口密度ベクトル (D,)\n",
    "        Ui_L (np.array): 各需要点におけるリーダーの影響度 (D,)\n",
    "        Ui_F (np.array): 各需要点におけるフォロワーの影響度 (D,)\n",
    "        wij (np.array): 需要点と施設候補の重み行列 (D, J)\n",
    "        x (np.array): リーダーが選択した施設配置 (J,)\n",
    "        y (np.array): フォロワーが選択した施設配置 (J,)\n",
    "\n",
    "    Returns:\n",
    "        float: L(x, y) の計算結果\n",
    "    \"\"\"\n",
    "    numerator = Ui_L + (wij @ x)  # 分子: リーダーの影響度 + 選択した施設の影響\n",
    "    denominator = Ui_L + Ui_F + (wij @ np.maximum(x, y))  # 分母: 総合影響度\n",
    "\n",
    "    return np.sum(h_i * (numerator / denominator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _moving_avg(x, w):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if len(x) < w:\n",
    "        return np.array([])\n",
    "    c = np.convolve(x, np.ones(w)/w, mode='valid')\n",
    "    return c\n",
    "\n",
    "def history_to_frame(history):\n",
    "    # Convert history dict {'objective','dx','dy', ...} into a tidy DataFrame with t index.\n",
    "    keys = sorted(history.keys())\n",
    "    L = max(len(history[k]) for k in keys)\n",
    "    data = {}\n",
    "    for k in keys:\n",
    "        v = np.asarray(history[k])\n",
    "        if v.ndim == 0:\n",
    "            v = np.array([v])\n",
    "        if len(v) < L:\n",
    "            pad = np.full(L - len(v), np.nan)\n",
    "            v = np.concatenate([v, pad])\n",
    "        data[k] = v\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index.name = \"t\"\n",
    "    return df\n",
    "\n",
    "def summarize_history(history, tol=1e-6, window=50):\n",
    "    # Return a dictionary of simple diagnostics from the history.\n",
    "    df = history_to_frame(history)\n",
    "    out = {}\n",
    "    if \"objective\" in df:\n",
    "        obj = df[\"objective\"].values\n",
    "        out[\"iters_recorded\"] = int(np.sum(~np.isnan(obj)))\n",
    "        if out[\"iters_recorded\"] > 1:\n",
    "            rel_changes = np.abs(np.diff(obj)) / (np.maximum(1.0, np.abs(obj[:-1])))\n",
    "            out[\"median_rel_obj_change\"] = float(np.nanmedian(rel_changes))\n",
    "            out[\"last_rel_obj_change\"] = float(rel_changes[-1])\n",
    "            deltas = np.diff(obj)\n",
    "            sign_flips = np.sum(np.sign(deltas[1:]) * np.sign(deltas[:-1]) < 0)\n",
    "            out[\"obj_sign_flips\"] = int(sign_flips)\n",
    "    for k in (\"dx\", \"dy\"):\n",
    "        if k in df:\n",
    "            s = df[k].values\n",
    "            out[f\"{k}_last\"] = float(s[~np.isnan(s)][-1]) if np.any(~np.isnan(s)) else float(\"nan\")\n",
    "            ma = _moving_avg(np.nan_to_num(s, nan=np.nan), min(window, max(1, np.sum(~np.isnan(s))//2 or 1)))\n",
    "            out[f\"{k}_moving_avg_last\"] = float(ma[-1]) if len(ma) else float(\"nan\")\n",
    "            out[f\"{k}_below_tol_ratio\"] = float(np.mean(np.nan_to_num(s, nan=np.inf) < tol)) if np.any(~np.isnan(s)) else float(\"nan\")\n",
    "    out[\"likely_stagnated\"] = bool(\n",
    "        out.get(\"dx_below_tol_ratio\", 0) > 0.8 and out.get(\"dy_below_tol_ratio\", 0) > 0.8\n",
    "    )\n",
    "    out[\"likely_oscillating\"] = bool(out.get(\"obj_sign_flips\", 0) > (out.get(\"iters_recorded\", 0) * 0.2))\n",
    "    return out\n",
    "\n",
    "def plot_history(history, tau_interval=None):\n",
    "    # Make simple plots for objective and step sizes. One plot per figure.\n",
    "    df = history_to_frame(history)\n",
    "    if \"objective\" in df:\n",
    "        plt.figure()\n",
    "        df[\"objective\"].plot()\n",
    "        plt.title(\"Objective per iteration\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.ylabel(\"objective\")\n",
    "        if tau_interval:\n",
    "            for t in range(tau_interval, len(df), tau_interval):\n",
    "                plt.axvline(t, linestyle=\"--\", alpha=0.2)\n",
    "        plt.show()\n",
    "    for k in (\"dx\", \"dy\"):\n",
    "        if k in df:\n",
    "            plt.figure()\n",
    "            df[k].plot()\n",
    "            plt.title(f\"{k} per iteration\")\n",
    "            plt.xlabel(\"iteration\")\n",
    "            plt.ylabel(k)\n",
    "            if tau_interval:\n",
    "                for t in range(tau_interval, len(df), tau_interval):\n",
    "                    plt.axvline(t, linestyle=\"--\", alpha=0.2)\n",
    "            plt.show()\n",
    "\n",
    "def save_history_csv(history, path=\"lgda_history.csv\"):\n",
    "    df = history_to_frame(history)\n",
    "    df.to_csv(path, index=True)\n",
    "    return path\n",
    "\n",
    "def mark_tau_events(length, tau_interval):\n",
    "    return [t for t in range(length) if (t % tau_interval) == 0 and t > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_convergence(history, tol=1e-6, patience=50):\n",
    "    \"\"\"\n",
    "    historyから収束判定を行い、\n",
    "    - 収束していれば 0\n",
    "    - 収束していなければ 1\n",
    "    を返す関数。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : dict\n",
    "        lgda_solver(..., return_history=True) で得られる辞書\n",
    "        {\"objective\": ..., \"dx\": ..., \"dy\": ...}\n",
    "    tol : float\n",
    "        許容誤差（dx, dy の閾値）\n",
    "    patience : int\n",
    "        連続して何回 tol を満たしたら「収束」とみなすか\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int : 0 (収束), 1 (非収束)\n",
    "    \"\"\"\n",
    "    dx = np.asarray(history.get(\"dx\", []))\n",
    "    dy = np.asarray(history.get(\"dy\", []))\n",
    "\n",
    "    if len(dx) == 0 or len(dy) == 0:\n",
    "        return 1  # データがなければ非収束扱い\n",
    "\n",
    "    # 末尾から patience 回分を確認\n",
    "    recent_dx = dx[-patience:]\n",
    "    recent_dy = dy[-patience:]\n",
    "\n",
    "    # すべて tol 以下なら収束と判定\n",
    "    if np.all(recent_dx < tol) and np.all(recent_dy < tol):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# scflp.py
# é€æ¬¡å‹ ç«¶äº‰çš„æ–½è¨­é…ç½®å•é¡Œ (S-CFLP) â€” Python å®Ÿè£…ï¼ˆãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ­ã‚°ç‰ˆï¼‰
# Branch-and-(outer)-Cut ã¨é…å»¶åˆ¶ç´„ç”Ÿæˆ (DCG)
# - ç›®çš„é–¢æ•°ã¨ãƒ¢ãƒ‡ãƒ«ã¯ Qi, Jiang, Shen (2022), arXiv:2103.04259v3 ã«æº–æ‹ 
# - ãƒ•ã‚©ãƒ­ãƒ¯å´ã®åˆ†é›¢ã¯å‘½é¡Œ5ã®è¿‘ä¼¼åˆ†é›¢ï¼ˆå˜ä¸€ã‚½ãƒ¼ãƒˆï¼‰ã‚’ä½¿ç”¨
# - 2ç¨®é¡ã®ã‚«ãƒƒãƒˆã‚’è¿½åŠ : Submodularï¼ˆæ•´æ•° x ã®ã¨ãï¼‰ã¨ Bulgeï¼ˆå¸¸ã«ï¼‰
#
# ä¾å­˜é–¢ä¿‚:
#   numpyï¼ˆå¿…é ˆï¼‰
#   PuLPï¼ˆæ¨å¥¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã¾ãŸã¯ gurobipyï¼ˆä»»æ„ã€MILP ã‚’é«˜é€Ÿã«è§£ãå ´åˆï¼‰
#
# å¤‰æ›´ç‚¹ï¼ˆãƒ­ã‚°å¼·åŒ–ï¼‰:
# - è¦ªã—ã¿ã‚„ã™ã„çµµæ–‡å­—ï¼†æ—¥æœ¬èªã§é€²æ—ã‚’è¡¨ç¤ºï¼ˆå„ãƒ©ã‚¦ãƒ³ãƒ‰ã®æ¦‚è¦ã€åˆ†é›¢ã®è¦ç´„ã€è¿½åŠ ã—ãŸã‚«ãƒƒãƒˆç­‰ï¼‰
# - ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: 'quiet' / 'info' / 'debug'
# - ä¾¿åˆ©ãªã¾ã¨ã‚å‡ºåŠ›ï¼ˆç·æ™‚é–“ãƒ»åå¾©æ•°ãƒ»è¿½åŠ ã‚«ãƒƒãƒˆæ•°ãƒ»é¸æŠã‚µã‚¤ãƒˆãƒ»æœ€çµ‚ã‚®ãƒ£ãƒƒãƒ—ãªã©ï¼‰

from __future__ import annotations

import time
import math
import shutil
import numpy as np
from typing import Dict, List, Optional, Tuple, Sequence, Set

# --- ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã® MILP ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ -------------------------------------------
# æœ€å°é™ã®æŠ½è±¡åŒ–ã«ã‚ˆã‚Šã€PuLP ã‹ Gurobi ã®ã©ã¡ã‚‰ã§ã‚‚å·®ã—æ›¿ãˆå¯èƒ½ã€‚
# æ—¢å®š: PuLP (CBC)ã€‚gurobipy ãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ 'gurobi' ã‚’é¸æŠå¯ã€‚


class _MILPVar:
    def __init__(self, name, index=None):
        self.name = f"{name}[{index}]" if index is not None else name


class _MILPInterface:
    def add_binary_var(self, name: str, index: Optional[int] = None):
        raise NotImplementedError

    def add_continuous_var(self, name: str, lb: float, ub: float):
        raise NotImplementedError

    def add_constraint_eq(self, expr, rhs, name: str):
        raise NotImplementedError

    def add_constraint_le(self, expr, rhs, name: str):
        raise NotImplementedError

    def set_objective_max(self, expr):
        raise NotImplementedError

    def solve(self) -> int:
        raise NotImplementedError

    def get_value(self, var) -> float:
        raise NotImplementedError

    def add_linear_cut_theta_le(
        self, theta, c0: float, coeffs: Dict[int, float], name: str
    ):
        # theta <= c0 + sum_j coeffs[j] * x_j
        lhs = theta
        rhs = c0
        expr = 0.0
        for j, cj in coeffs.items():
            expr += cj * self.x[j]  # type: ignore
        # å®Ÿè£…å½¢: theta - sum_j coeffs_j x_j <= c0
        self.add_constraint_le(lhs - expr, rhs, name)


class PuLPInterface(_MILPInterface):
    def __init__(self, nJ: int, p: int, solver_name: str = "CBC"):
        import pulp  # type: ignore

        self.pulp = pulp
        self.model = pulp.LpProblem("S_CFLP_Master", pulp.LpMaximize)
        self.x = {
            j: pulp.LpVariable(f"x[{j}]", lowBound=0, upBound=1, cat="Binary")
            for j in range(nJ)
        }
        self.theta = pulp.LpVariable(
            "theta", lowBound=0.0, upBound=1.0, cat="Continuous"
        )
        # äºˆç®—åˆ¶ç´„
        self.model += pulp.lpSum([self.x[j] for j in range(nJ)]) == p, "budget_eq"
        # ç›®çš„
        self.model += self.theta, "obj"
        if solver_name == "CBC":
            self.solver = pulp.PULP_CBC_CMD(msg=False)
        elif solver_name == "GLPK":
            self.solver = pulp.GLPK_CMD(msg=False)
        else:
            self.solver = pulp.PULP_CBC_CMD(msg=False)

    def add_binary_var(self, name: str, index: Optional[int] = None):
        raise NotImplementedError("Binary x_j created in constructor.")

    def add_continuous_var(self, name: str, lb: float, ub: float):
        raise NotImplementedError("Continuous theta created in constructor.")

    def add_constraint_eq(self, expr, rhs, name: str):
        self.model += (expr == rhs), name

    def add_constraint_le(self, expr, rhs, name: str):
        self.model += (expr <= rhs), name

    def set_objective_max(self, expr):
        self.model.sense = self.pulp.LpMaximize
        self.model.setObjective(expr)

    def solve(self) -> int:
        status = self.model.solve(self.solver)
        return int(status)

    def get_value(self, var) -> float:
        return float(var.value())


class GurobiInterface(_MILPInterface):
    def __init__(self, nJ: int, p: int):
        import gurobipy as gp  # type: ignore
        from gurobipy import GRB

        self.gp = gp
        self.model = gp.Model("S_CFLP_Master")
        self.model.Params.OutputFlag = 0
        self.x = {
            j: self.model.addVar(vtype=GRB.BINARY, name=f"x[{j}]") for j in range(nJ)
        }
        self.theta = self.model.addVar(
            lb=0.0, ub=1.0, vtype=GRB.CONTINUOUS, name="theta"
        )
        # äºˆç®—åˆ¶ç´„
        self.model.addConstr(
            self.gp.quicksum(self.x[j] for j in range(nJ)) == p, name="budget_eq"
        )
        # ç›®çš„
        self.model.setObjective(self.theta, GRB.MAXIMIZE)

    def add_binary_var(self, name: str, index: Optional[int] = None):
        raise NotImplementedError("Binary x_j created in constructor.")

    def add_continuous_var(self, name: str, lb: float, ub: float):
        raise NotImplementedError("Continuous theta created in constructor.")

    def add_constraint_eq(self, expr, rhs, name: str):
        self.model.addConstr(expr == rhs, name=name)

    def add_constraint_le(self, expr, rhs, name: str):
        self.model.addConstr(expr <= rhs, name=name)

    def set_objective_max(self, expr):
        from gurobipy import GRB

        self.model.setObjective(expr, GRB.MAXIMIZE)

    def solve(self) -> int:
        self.model.optimize()
        return int(self.model.Status)

    def get_value(self, var) -> float:
        return float(var.X)


# --- å•é¡Œãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒ†ãƒŠ ------------------------------------------------------


class SCFLPData:
    """
    MNL åŠ¹ç”¨ã®ã‚‚ã¨ã§ã® S-CFLP ã®ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ãƒŠã€‚

    Attributes
    ----------
    I : int                   # éœ€è¦ç‚¹ã®æ•°
    J : int                   # å€™è£œåœ°ã®æ•°
    h : (I,) array            # éœ€è¦é‡ã¿ï¼ˆåˆè¨ˆ 1ï¼‰
    UL : (I,) array           # æ—¢å­˜ãƒªãƒ¼ãƒ€ãƒ¼æ–½è¨­ã®åŠ¹ç”¨
    UF : (I,) array           # æ—¢å­˜ãƒ•ã‚©ãƒ­ãƒ¯æ–½è¨­ã®åŠ¹ç”¨
    w  : (I,J) array          # å€™è£œã«å¯¾ã™ã‚‹ w_ij = exp(alpha_j - beta * d_ij)
    p  : int                  # ãƒªãƒ¼ãƒ€ãƒ¼ã®äºˆç®—ï¼ˆæ–°è¨­æ•°ï¼‰
    r  : int                  # ãƒ•ã‚©ãƒ­ãƒ¯ã®äºˆç®—
    """

    def __init__(
        self,
        h: np.ndarray,
        UL: np.ndarray,
        UF: np.ndarray,
        w: np.ndarray,
        p: int,
        r: int,
    ):
        assert h.ndim == 1 and UL.ndim == 1 and UF.ndim == 1
        assert w.ndim == 2 and w.shape[0] == h.shape[0]
        self.h = h.astype(float)
        self.UL = UL.astype(float)
        self.UF = UF.astype(float)
        self.w = w.astype(float)
        self.I = h.shape[0]
        self.J = w.shape[1]
        self.p = int(p)
        self.r = int(r)
        s = self.h.sum()
        if abs(s - 1.0) > 1e-12:
            self.h = self.h / s

    @staticmethod
    def from_coordinates(
        demand_xy: np.ndarray,
        cand_xy: np.ndarray,
        alpha: np.ndarray,
        beta: float,
        p: int,
        r: int,
        leader_xy: Optional[np.ndarray] = None,
        follower_xy: Optional[np.ndarray] = None,
        h: Optional[np.ndarray] = None,
    ) -> "SCFLPData":
        """
        2æ¬¡å…ƒåº§æ¨™ã‹ã‚‰ã®ç°¡æ˜“ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã€‚
        """
        I = demand_xy.shape[0]
        J = cand_xy.shape[0]
        if h is None:
            h = np.ones(I) / I

        def pairwise_dist(A, B):
            return np.sqrt(((A[:, None, :] - B[None, :, :]) ** 2).sum(axis=2))

        d_cand = pairwise_dist(demand_xy, cand_xy)  # (I,J)
        w = np.exp(alpha.reshape(1, J) - beta * d_cand)

        UL = np.zeros(I)
        UF = np.zeros(I)
        if leader_xy is not None and leader_xy.shape[0] > 0:
            dL = pairwise_dist(demand_xy, leader_xy)
            wL = np.exp(alpha.mean() - beta * dL)  # æ—¢å­˜ã«ã‚‚å¹³å‡ Î± ã‚’ä»®å®š
            UL = wL.sum(axis=1)
        if follower_xy is not None and follower_xy.shape[0] > 0:
            dF = pairwise_dist(demand_xy, follower_xy)
            wF = np.exp(alpha.mean() - beta * dF)
            UF = wF.sum(axis=1)

        return SCFLPData(h=h, UL=UL, UF=UF, w=w, p=p, r=r)


# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° --------------------------------------------------------


def L_value(data: SCFLPData, x: np.ndarray, y: np.ndarray) -> float:
    """
    å¼(4)ã® L(x, y) ã‚’è¨ˆç®—:  Î¸ â‰¤ L(x,y) ã§ä½¿ã†çœŸã®è©•ä¾¡å€¤
      L(x,y) = sum_i h_i * (UL_i + sum_j w_ij x_j) / (UL_i + UF_i + sum_j w_ij (x_j OR y_j))
    """
    J = data.J
    x = x.reshape(J)
    y = y.reshape(J)
    xy = np.maximum(x, y)  # x âˆ¨ y
    num = data.UL + data.w.dot(x)
    den = data.UL + data.UF + data.w.dot(xy)
    return float((data.h * (num / den)).sum())


def Lb_and_grad(
    data: SCFLPData, x: np.ndarray, y: np.ndarray
) -> Tuple[float, np.ndarray]:
    """
    Bulge é–¢æ•° L_b(x, y) ã¨ã€ãã®ç‚¹ (x,y) ã«ãŠã‘ã‚‹ x ã«é–¢ã™ã‚‹å‹¾é…ã€‚
    ï¼ˆå¼(11) ã®æ¥å¹³é¢ã‚’åˆ‡æ–­ã¨ã—ã¦ä½¿ã†ï¼‰
    """
    J = data.J
    x = x.reshape(J)
    y = y.reshape(J)
    one_minus_y = 1.0 - y
    P = data.UL + data.UF + data.w.dot(one_minus_y * x + y)  # (I,)
    Q = data.UL + data.w.dot(-y * (x**2) + (1.0 + y) * x)  # (I,)
    Lb = (data.h * (Q / P)).sum()
    grad = np.zeros(J)
    P2 = P * P
    for j in range(J):
        wj = data.w[:, j]
        term = (
            -wj * one_minus_y[j] * Q / P2 + wj * (-2.0 * y[j] * x[j] + 1.0 + y[j]) / P
        )
        grad[j] = (data.h * term).sum()
    return float(Lb), grad


def submodular_cut_coeffs(
    data: SCFLPData, x_bin: np.ndarray, y_bin: np.ndarray
) -> Tuple[float, Dict[int, float]]:
    """
    å›ºå®šã•ã‚ŒãŸ Y ã®ä¸‹ã§ã€S = supp(x) ã‚’ç”¨ã„ã¦ Nemhauserâ€“Wolsey ç·šå½¢åŒ–ã‚’æ§‹ç¯‰ï¼ˆå¼(8)ï¼‰ã€‚
    è¿”ã‚Šå€¤ (c0, coeffs) ã¯ä¸ç­‰å¼ Î¸ <= c0 + sum_j coeffs[j] * x_j ã®ä¿‚æ•°ã€‚
    """
    J = data.J
    S: Set[int] = set(np.where(x_bin > 0.5)[0].tolist())
    Y: Set[int] = set(np.where(y_bin > 0.5)[0].tolist())

    def L_Y_of_X(Xset: Set[int]) -> float:
        maskX = np.zeros(J, dtype=float)
        if Xset:
            maskX[list(Xset)] = 1.0
        maskXUY = maskX.copy()
        if Y:
            maskY = np.zeros(J, dtype=float)
            maskY[list(Y)] = 1.0
            maskXUY = np.maximum(maskX, maskY)
        num = data.UL + data.w.dot(maskX)
        den = data.UL + data.UF + data.w.dot(maskXUY)
        return float((data.h * (num / den)).sum())

    LYS = L_Y_of_X(S)
    rho_S_k: Dict[int, float] = {}
    for k in range(J):
        if k in S:
            continue
        Sk = set(S)
        Sk.add(k)
        rho_S_k[k] = L_Y_of_X(Sk) - LYS

    rho_Jminus_k_k: Dict[int, float] = {}
    J_minus_k_base = set(range(J))
    for k in range(J):
        Sfull_minus_k = set(J_minus_k_base)
        Sfull_minus_k.remove(k)
        LY_full_minus_k = L_Y_of_X(Sfull_minus_k)
        Sfull = set(J_minus_k_base)
        rho_Jminus_k_k[k] = L_Y_of_X(Sfull) - LY_full_minus_k

    c0 = LYS - sum(rho_Jminus_k_k[k] for k in S)
    coeffs: Dict[int, float] = {}
    for k in S:
        coeffs[k] = rho_Jminus_k_k[k]
    for k in range(J):
        if k not in S:
            coeffs[k] = rho_S_k[k]
    return c0, coeffs


def approximate_separation_y(
    data: SCFLPData, x: np.ndarray
) -> Tuple[np.ndarray, float, np.ndarray]:
    """
    å‘½é¡Œ5ã®è¿‘ä¼¼åˆ†é›¢ï¼ˆp.16â€“17ï¼‰ã€‚
      - Î±(x) ã¨ Î²(x) ã‚’é–‰å½¢å¼ã§è¨ˆç®—
      - y_hat ã¯ Î²(x) é™é †ã« r å€‹
      - æˆ»ã‚Šå€¤: (y_hat, ub_lin = Î±(x) - Î²^T y_hat, beta)
    """
    J = data.J
    x = x.reshape(J)
    I = data.I
    a = data.UL + data.w.dot(x)  # (I,)
    w_scaled = data.w * (1.0 - x.reshape(1, J))  # (I,J)
    r = data.r
    smallest = (
        np.partition(w_scaled, r - 1, axis=1)[:, :r].sum(axis=1)
        if r > 0
        else np.zeros(I)
    )
    largest = (
        (-np.partition(-w_scaled, r - 1, axis=1)[:, :r]).sum(axis=1)
        if r > 0
        else np.zeros(I)
    )
    wL = data.UF + smallest
    wU = data.UF + largest

    denomL = a + wL
    denomU = a + wU
    alpha_terms = a * (a + wU + wL - data.UF) / (denomU * denomL)
    alpha_val = float((data.h * alpha_terms).sum())

    common = data.h * (a / (denomU * denomL))  # (I,)
    beta = (common.reshape(I, 1) * (data.w * (1.0 - x.reshape(1, J)))).sum(
        axis=0
    )  # (J,)

    idx_sorted = np.argsort(-beta)
    y_hat = np.zeros(J)
    if r > 0:
        y_hat[idx_sorted[:r]] = 1.0
    ub_lin = alpha_val - float(beta[y_hat > 0.5].sum())
    return y_hat, ub_lin, beta


# --- ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãƒ»ãƒ­ã‚¬ãƒ¼ ------------------------------------------------------


class FriendlyLogger:
    def __init__(
        self, level: str = "info", enabled: bool = True, width: Optional[int] = None
    ):
        self.level = level.lower()
        self.enabled = enabled
        self.start = time.time()
        try:
            self.width = width or shutil.get_terminal_size((100, 20)).columns
        except Exception:
            self.width = 100

    def _ok(self) -> bool:
        return self.enabled and self.level in ("info", "debug")

    def _dbg(self) -> bool:
        return self.enabled and self.level == "debug"

    def line(self, char: str = "â”€"):
        if not self._ok():
            return
        print(char * min(self.width, 80))

    def header(self, title: str):
        if not self._ok():
            return
        self.line("â•")
        print(f"ğŸš€ {title}")
        self.line("â•")

    def step(self, msg: str):
        if not self._ok():
            return
        print(f"â¤ {msg}")

    def debug(self, msg: str):
        if not self._dbg():
            return
        print(f"   Â· {msg}")

    def cut(self, kinds: List[str]):
        if not self._ok():
            return
        tag = " + ".join(kinds).upper()
        print(f"âœ‚ï¸  ã‚«ãƒƒãƒˆè¿½åŠ : {tag}")

    def success(self, msg: str):
        if not self._ok():
            return
        print(f"âœ… {msg}")

    def warn(self, msg: str):
        if not self._ok():
            return
        print(f"âš ï¸  {msg}")

    def done(self, msg: str):
        if not self._ok():
            return
        elapsed = time.time() - self.start
        print(f"ğŸ {msg}ï¼ˆçµŒé {elapsed:.2f}sï¼‰")
        self.line("â•")


# --- ãƒ¡ã‚¤ãƒ³ã‚½ãƒ«ãƒ --------------------------------------------------------------


class SCFLPSolver:
    """
    è¿‘ä¼¼åˆ†é›¢ï¼ˆå‘½é¡Œ5ï¼‰ã¨ 2 ç¨®ã®ã‚«ãƒƒãƒˆï¼ˆSubmodular, Bulgeï¼‰ã‚’ç”¨ã„ãŸ DCG ã«ã‚ˆã‚Š S-CFLP ã‚’è§£ãã€‚
    gurobipy ãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ milp_backend='gurobi' ã‚’æ¨å¥¨ã€‚æ—¢å®šã¯ PuLP (CBC)ã€‚
    """

    def __init__(
        self,
        data: SCFLPData,
        milp_backend: str = "pulp",
        pulp_solver: str = "CBC",
        log_level: str = "info",
    ):
        self.data = data
        self.backend_name = milp_backend
        if milp_backend == "gurobi":
            try:
                self.mip = GurobiInterface(nJ=data.J, p=data.p)
            except Exception as e:
                print("Gurobi ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ PuLP ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™:", e)
                self.mip = PuLPInterface(nJ=data.J, p=data.p, solver_name=pulp_solver)
        else:
            self.mip = PuLPInterface(nJ=data.J, p=data.p, solver_name=pulp_solver)

        self.theta = self.mip.theta
        self.xvars = self.mip.x  # dict j->var

        # ãƒ­ã‚°
        self.logger = FriendlyLogger(level=log_level, enabled=True)

        # ãƒ­ã‚°æƒ…å ±
        self.cuts_added: int = 0
        self.iterations: int = 0
        self.cuts_log: List[Tuple[str, float]] = []  # (ç¨®åˆ¥, å€¤)

    # å†…éƒ¨ãƒ˜ãƒ«ãƒ‘
    def _current_solution(self) -> Tuple[np.ndarray, float]:
        x_hat = np.array(
            [self.mip.get_value(self.xvars[j]) for j in range(self.data.J)], dtype=float
        )
        theta_hat = float(self.mip.get_value(self.theta))
        return x_hat, theta_hat

    def _add_bulge_cut(self, x_hat: np.ndarray, y_hat: np.ndarray):
        Lb, grad = Lb_and_grad(self.data, x_hat, y_hat)
        c0 = Lb - float((grad * x_hat).sum())
        coeffs = {j: float(grad[j]) for j in range(self.data.J) if abs(grad[j]) > 1e-12}
        self.mip.add_linear_cut_theta_le(
            self.theta, c0, coeffs, name=f"bulge_cut_{self.cuts_added}"
        )
        self.cuts_added += 1
        self.cuts_log.append(("bulge", Lb))

    def _add_submodular_cut_if_integer(
        self, x_hat: np.ndarray, y_hat: np.ndarray
    ) -> bool:
        if np.all((x_hat < 1e-6) | (x_hat > 1 - 1e-6)):
            x_bin = (x_hat > 0.5).astype(float)
            y_bin = (y_hat > 0.5).astype(float)
            c0, coeffs = submodular_cut_coeffs(self.data, x_bin, y_bin)
            self.mip.add_linear_cut_theta_le(
                self.theta, c0, coeffs, name=f"submod_cut_{self.cuts_added}"
            )
            self.cuts_added += 1
            self.cuts_log.append(("submod", c0))
            return True
        return False

    def _format_top(self, beta: np.ndarray, k: int = 5) -> str:
        k = min(k, len(beta))
        idx = np.argsort(-beta)[:k]
        pairs = [f"j={int(j)}: Î²={beta[j]:.4g}" for j in idx]
        return ", ".join(pairs)

    def solve(
        self, max_rounds: int = 200, tol: float = 1e-8, verbose: bool = True
    ) -> Dict[str, object]:
        """
        DCG ã®ä¸»ãƒ«ãƒ¼ãƒ—ï¼ˆå¤–å´ cutting-planeï¼‰:
          1) ãƒã‚¹ã‚¿ MILP ã‚’è§£ãï¼ˆÎ¸ æœ€å¤§åŒ–, Î£x=pï¼‰
          2) è¿‘ä¼¼åˆ†é›¢ã§ y_hat ã‚’å–å¾—ï¼ˆÎ² é™é †ã« r å€‹ï¼‰
          3) çœŸã® L(x_hat,y_hat) ã‚’è©•ä¾¡ã€‚é•åãªã‚‰ Bulgeï¼ˆï¼‹æ•´æ•°ãªã‚‰ Submodularï¼‰ã‚’è¿½åŠ 
          4) é•åãªã—ã§åœæ­¢
        """
        self.logger.header("S-CFLP ã‚’è§£ãã¾ã™ï¼ˆDCG + Bulge/Submodular ã‚«ãƒƒãƒˆï¼‰")
        self.logger.step(
            f"å€™è£œåœ° J = {self.data.J}, éœ€è¦ç‚¹ I = {self.data.I}, p = {self.data.p}, r = {self.data.r}"
        )

        t0 = time.time()
        for it in range(1, max_rounds + 1):
            self.iterations = it
            it_start = time.time()
            status = self.mip.solve()
            x_hat, theta_hat = self._current_solution()
            is_int = bool(np.all((x_hat < 1e-6) | (x_hat > 1 - 1e-6)))
            self.logger.line()
            self.logger.step(
                f"ğŸ§® ãƒ©ã‚¦ãƒ³ãƒ‰ {it}: master è§£ â†’ \hat(Î¸) = {theta_hat:.6f}, "
                f"|x| = {x_hat.sum():.0f}/{self.data.p}ï¼ˆ{'æ•´æ•°' if is_int else 'å°æ•°æ··åœ¨'}ï¼‰"
            )

            # åˆ†é›¢ï¼ˆå‘½é¡Œ5ï¼‰
            y_hat, ub_lin, beta = approximate_separation_y(self.data, x_hat)
            y_idx = np.where(y_hat > 0.5)[0].tolist()
            true_val = L_value(self.data, x_hat, y_hat)
            gap = theta_hat - true_val
            self.logger.step(
                f"ğŸ” åˆ†é›¢ï¼šyÌ‚ ã¯ {y_idx}ï¼ˆr = {self.data.r}ï¼‰ã€‚ä¸Šç•Œ Î± âˆ’ Î²áµ€yÌ‚ = {ub_lin:.6f}"
            )
            self.logger.debug(
                f"Î² ä¸Šä½: {self._format_top(beta, k=min(5, self.data.J))}"
            )
            self.logger.step(
                f"ğŸ“ è©•ä¾¡ï¼šL(xÌ‚,yÌ‚) = {true_val:.6f} â†’ é•åé‡ \hat(Î¸) - L = {gap:.3e}"
            )

            if theta_hat > true_val + tol:
                kinds = ["bulge"]
                self._add_bulge_cut(x_hat, y_hat)
                added_sub = self._add_submodular_cut_if_integer(x_hat, y_hat)
                if added_sub:
                    kinds.append("submod")
                self.logger.cut(kinds)
                self.logger.debug(f"ç¾åœ¨ã®ã‚«ãƒƒãƒˆç·æ•°: {self.cuts_added}")
                self.logger.debug(f"ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰æ‰€è¦: {time.time()-it_start:.2f}s")
                continue
            else:
                self.logger.success("é•åãªã—ã€‚ç¾åœ¨ã® Y-closure ã«å¯¾ã—ã¦æœ€é©ã§ã™ã€‚")
                break

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        status = self.mip.solve()
        x_hat, theta_hat = self._current_solution()
        elapsed = time.time() - t0
        sel = np.where(x_hat > 0.5)[0].tolist()

        self.logger.done("æ±‚è§£å®Œäº†")
        self.logger.step(f"âœ¨ ç›®çš„å€¤ Î¸ = {theta_hat:.6f} / é¸æŠã‚µã‚¤ãƒˆ {sel}")
        self.logger.step(
            f"ğŸ§· åå¾© {self.iterations} å›ãƒ»è¿½åŠ ã‚«ãƒƒãƒˆ {self.cuts_added} æœ¬ãƒ»åˆè¨ˆæ™‚é–“ {elapsed:.2f}s"
        )
        if abs(x_hat.sum() - self.data.p) > 1e-6:
            self.logger.warn("Î£x ãŒ p ã¨ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚äºˆç®—åˆ¶ç´„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return dict(
            x=x_hat,
            theta=theta_hat,
            obj=theta_hat,
            status=status,
            iterations=self.iterations,
            cuts=self.cuts_added,
            cuts_log=self.cuts_log,
            selected_sites=sel,
            time_sec=elapsed,
        )


# --- ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ˜ãƒ«ãƒ‘ --------------------------------------------------------


def make_random_instance(
    I: int = 10,
    J: int = 10,
    p: int = 2,
    r: int = 2,
    beta: float = 0.1,
    alpha_mean: float = 0.0,
    alpha_std: float = 0.0,
    seed: int = 0,
) -> SCFLPData:
    """
    [0,50] x [0,50] ä¸Šã«ãƒ©ãƒ³ãƒ€ãƒ ãªå¹³é¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆï¼ˆè«–æ–‡ã®å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼‰ã€‚
    """
    rng = np.random.default_rng(seed)
    demand_xy = rng.uniform(0, 50, size=(I, 2))
    cand_xy = rng.uniform(0, 50, size=(J, 2))
    alpha = rng.normal(loc=alpha_mean, scale=alpha_std, size=(J,))
    return SCFLPData.from_coordinates(
        demand_xy=demand_xy, cand_xy=cand_xy, alpha=alpha, beta=beta, p=p, r=r
    )


if __name__ == "__main__":
    data = make_random_instance(I=40, J=30, p=3, r=2, beta=0.1, seed=42)
    solver = SCFLPSolver(data, milp_backend="pulp", pulp_solver="CBC", log_level="info")
    res = solver.solve(max_rounds=200, verbose=True)
    print("\nSolved: theta=", res["theta"], " sum x=", res["x"].sum(), "p=", data.p)

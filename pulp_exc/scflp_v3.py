# scflp_fn.py
# é€æ¬¡å‹ ç«¶äº‰çš„æ–½è¨­é…ç½®å•é¡Œ (S-CFLP) â€” é–¢æ•°ç‰ˆï¼ˆãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ­ã‚°ï¼‰
# ãƒ»Branch-and-(outer)-Cut + é…å»¶åˆ¶ç´„ç”Ÿæˆï¼ˆDCGï¼‰
# ãƒ»ãƒ•ã‚©ãƒ­ãƒ¯å´ã®åˆ†é›¢ã¯å‘½é¡Œ5ã®è¿‘ä¼¼åˆ†é›¢ï¼ˆå˜ä¸€ã‚½ãƒ¼ãƒˆï¼‰
# ãƒ»è¿½åŠ ã‚«ãƒƒãƒˆ: Bulgeï¼ˆå¸¸ã«ï¼‰ / Submodularï¼ˆxãŒæ•´æ•°ã®ã¨ãï¼‰
# ãƒ»MILPã¯PuLP(CBC/GLPK)ã®ã¿ã‚’ä½¿ç”¨ï¼ˆç°¡ç´ åŒ–ã®ãŸã‚ï¼‰

from __future__ import annotations

import time
import shutil
import numpy as np
from typing import Dict, List, Optional, Tuple, Set

# ========== ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»å‰å‡¦ç†ï¼ˆã‚¯ãƒ©ã‚¹å»ƒæ­¢ã€dictã§æ‰±ã†ï¼‰ =========================


def normalize_h(h: np.ndarray) -> np.ndarray:
    s = float(h.sum())
    return h / s if abs(s - 1.0) > 1e-12 else h


def scflp_from_coordinates(
    demand_xy: np.ndarray,
    cand_xy: np.ndarray,
    alpha: np.ndarray,
    beta: float,
    p: int,
    r: int,
    leader_xy: Optional[np.ndarray] = None,
    follower_xy: Optional[np.ndarray] = None,
    h: Optional[np.ndarray] = None,
) -> Dict[str, object]:
    """2æ¬¡å…ƒåº§æ¨™ã‹ã‚‰S-CFLPãƒ‡ãƒ¼ã‚¿(dict)ã‚’ä½œã‚‹ã€‚"""
    I, J = demand_xy.shape[0], cand_xy.shape[0]
    h = normalize_h(np.ones(I) / I if h is None else h.astype(float))
    alpha = alpha.reshape(J)

    def pairwise_dist(A, B):
        return np.sqrt(((A[:, None, :] - B[None, :, :]) ** 2).sum(axis=2))

    d_cand = pairwise_dist(demand_xy, cand_xy)
    w = np.exp(alpha.reshape(1, J) - beta * d_cand)

    UL = np.zeros(I)
    UF = np.zeros(I)
    if leader_xy is not None and len(leader_xy) > 0:
        dL = pairwise_dist(demand_xy, leader_xy)
        wL = np.exp(alpha.mean() - beta * dL)
        UL = wL.sum(axis=1)
    if follower_xy is not None and len(follower_xy) > 0:
        dF = pairwise_dist(demand_xy, follower_xy)
        wF = np.exp(alpha.mean() - beta * dF)
        UF = wF.sum(axis=1)

    return dict(h=h, UL=UL, UF=UF, w=w, I=I, J=J, p=int(p), r=int(r))


def make_random_instance(
    I: int = 10,
    J: int = 10,
    p: int = 2,
    r: int = 2,
    beta: float = 0.1,
    alpha_mean: float = 0.0,
    alpha_std: float = 0.0,
    seed: int = 0,
) -> Dict[str, object]:
    rng = np.random.default_rng(seed)
    demand_xy = rng.uniform(0, 50, size=(I, 2))
    cand_xy = rng.uniform(0, 50, size=(J, 2))
    alpha = rng.normal(loc=alpha_mean, scale=alpha_std, size=(J,))
    return scflp_from_coordinates(demand_xy, cand_xy, alpha, beta, p, r)


# ========== ç›®çš„é–¢æ•°ãƒ»è©•ä¾¡ãƒ»åˆ†é›¢ãƒ»ã‚«ãƒƒãƒˆä¿‚æ•° ====================================


def L_value(data: Dict[str, object], x: np.ndarray, y: np.ndarray) -> float:
    """å¼(4)ã®çœŸå€¤ L(x,y)ã€‚"""
    w = data["w"]
    UL = data["UL"]
    UF = data["UF"]
    h = data["h"]
    x = x.reshape(-1)
    y = y.reshape(-1)
    xy = np.maximum(x, y)
    num = UL + w.dot(x)
    den = UL + UF + w.dot(xy)
    return float((h * (num / den)).sum())


def Lb_and_grad(
    data: Dict[str, object], x: np.ndarray, y: np.ndarray
) -> Tuple[float, np.ndarray]:
    """Bulgeé–¢æ•° L_b(x,y) ã¨ xå‹¾é…ï¼ˆå¼(11)ã®æ¥å¹³é¢ï¼‰ã€‚"""
    w = data["w"]
    UL = data["UL"]
    UF = data["UF"]
    h = data["h"]
    J = w.shape[1]
    x = x.reshape(J)
    y = y.reshape(J)
    one_minus_y = 1.0 - y
    P = UL + UF + w.dot(one_minus_y * x + y)  # (I,)
    Q = UL + w.dot(-y * (x**2) + (1.0 + y) * x)  # (I,)
    Lb = (h * (Q / P)).sum()
    grad = np.zeros(J)
    P2 = P * P
    for j in range(J):
        wj = w[:, j]
        term = (
            -wj * one_minus_y[j] * Q / P2 + wj * (-2.0 * y[j] * x[j] + 1.0 + y[j]) / P
        )
        grad[j] = (h * term).sum()
    return float(Lb), grad


def submodular_cut_coeffs(
    data: Dict[str, object], x_bin: np.ndarray, y_bin: np.ndarray
) -> Tuple[float, Dict[int, float]]:
    """Nemhauserâ€“Wolsey ç·šå½¢åŒ–ã®ä¿‚æ•°ï¼ˆå›ºå®šYä¸‹ã€å¼(8)ï¼‰ã€‚"""
    w = data["w"]
    UL = data["UL"]
    UF = data["UF"]
    h = data["h"]
    J = w.shape[1]
    S: Set[int] = set(np.where(x_bin > 0.5)[0].tolist())
    Y: Set[int] = set(np.where(y_bin > 0.5)[0].tolist())

    def L_Y_of_X(Xset: Set[int]) -> float:
        maskX = np.zeros(J)
        if Xset:
            maskX[list(Xset)] = 1.0
        maskXUY = maskX
        if Y:
            maskY = np.zeros(J)
            maskY[list(Y)] = 1.0
            maskXUY = np.maximum(maskX, maskY)
        num = UL + w.dot(maskX)
        den = UL + UF + w.dot(maskXUY)
        return float((h * (num / den)).sum())

    LYS = L_Y_of_X(S)

    rho_S_k: Dict[int, float] = {}
    for k in range(J):
        if k in S:
            continue
        Sk = set(S)
        Sk.add(k)
        rho_S_k[k] = L_Y_of_X(Sk) - LYS

    rho_Jminus_k_k: Dict[int, float] = {}
    Jall = set(range(J))
    for k in range(J):
        full_minus_k = set(Jall)
        full_minus_k.remove(k)
        LY_full_minus_k = L_Y_of_X(full_minus_k)
        rho_Jminus_k_k[k] = L_Y_of_X(Jall) - LY_full_minus_k

    c0 = LYS - sum(rho_Jminus_k_k[k] for k in S)
    coeffs: Dict[int, float] = {}
    for k in S:
        coeffs[k] = rho_Jminus_k_k[k]
    for k in range(J):
        if k not in S:
            coeffs[k] = rho_S_k[k]
    return c0, coeffs


def approximate_separation_y(
    data: Dict[str, object], x: np.ndarray
) -> Tuple[np.ndarray, float, np.ndarray]:
    """å‘½é¡Œ5ã®è¿‘ä¼¼åˆ†é›¢ã€‚y_hat, ub_lin, beta ã‚’è¿”ã™ã€‚"""
    w = data["w"]
    UL = data["UL"]
    UF = data["UF"]
    h = data["h"]
    r = data["r"]
    I, J = w.shape
    x = x.reshape(J)
    a = UL + w.dot(x)  # (I,)
    w_scaled = w * (1.0 - x.reshape(1, J))  # (I,J)

    smallest = (
        np.partition(w_scaled, r - 1, axis=1)[:, :r].sum(axis=1)
        if r > 0
        else np.zeros(I)
    )
    largest = (
        (-np.partition(-w_scaled, r - 1, axis=1)[:, :r]).sum(axis=1)
        if r > 0
        else np.zeros(I)
    )
    wL = UF + smallest
    wU = UF + largest

    denomL = a + wL
    denomU = a + wU
    alpha_terms = a * (a + wU + wL - UF) / (denomU * denomL)
    alpha_val = float((h * alpha_terms).sum())
    common = h * (a / (denomU * denomL))
    beta = (common.reshape(I, 1) * (w * (1.0 - x.reshape(1, J)))).sum(axis=0)

    idx_sorted = np.argsort(-beta)
    y_hat = np.zeros(J)
    if r > 0:
        y_hat[idx_sorted[:r]] = 1.0
    ub_lin = alpha_val - float(beta[y_hat > 0.5].sum())
    return y_hat, ub_lin, beta


# ========== MILPï¼ˆPuLPï¼‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========================================


def build_master_pulp(nJ: int, p: int, solver_name: str = "CBC"):
    import pulp  # lazy import

    model = pulp.LpProblem("S_CFLP_Master", pulp.LpMaximize)
    x = {
        j: pulp.LpVariable(f"x[{j}]", lowBound=0, upBound=1, cat="Binary")
        for j in range(nJ)
    }
    theta = pulp.LpVariable("theta", lowBound=0.0, upBound=1.0, cat="Continuous")
    # äºˆç®—åˆ¶ç´„ã¨ç›®çš„
    model += pulp.lpSum([x[j] for j in range(nJ)]) == p, "budget_eq"
    model += theta, "obj"
    if solver_name == "CBC":
        solver = pulp.PULP_CBC_CMD(msg=False)
    elif solver_name == "GLPK":
        solver = pulp.GLPK_CMD(msg=False)
    else:
        solver = pulp.PULP_CBC_CMD(msg=False)
    return model, x, theta, solver


def solve_master(model, solver) -> int:
    return int(model.solve(solver))


def get_values_pulp(xvars: Dict[int, object], theta) -> Tuple[np.ndarray, float]:
    x_hat = np.array([float(v.value()) for j, v in sorted(xvars.items())], dtype=float)
    return x_hat, float(theta.value())


def add_linear_cut_theta_le(
    model, theta, c0: float, coeffs: Dict[int, float], name: str
):
    """theta <= c0 + sum_j coeffs_j x_j  ã‚’  theta - sum <= c0 ã§è¿½åŠ """
    expr = 0.0
    for j, cj in coeffs.items():
        expr += cj * model.variablesDict()[f"x[{j}]"]
    model += (theta - expr <= c0), name


# ========== ãƒ­ã‚°ï¼ˆé–¢æ•°ç‰ˆï¼‰ =====================================================


def _term_width(default=100) -> int:
    try:
        return shutil.get_terminal_size((default, 20)).columns
    except Exception:
        return default


def log_header(title: str, level: str):
    if level not in ("info", "debug"):
        return
    w = min(_term_width(), 80)
    print("â•" * w)
    print(f"ğŸš€ {title}")
    print("â•" * w)


def log_line(level: str, char="â”€"):
    if level not in ("info", "debug"):
        return
    print(char * min(_term_width(), 80))


def log_step(msg: str, level: str):
    if level not in ("info", "debug"):
        return
    print(f"â¤ {msg}")


def log_debug(msg: str, level: str):
    if level != "debug":
        return
    print(f"   Â· {msg}")


def log_cut(kinds: List[str], level: str):
    if level not in ("info", "debug"):
        return
    print(f"âœ‚ï¸  ã‚«ãƒƒãƒˆè¿½åŠ : {' + '.join(kinds).upper()}")


def log_success(msg: str, level: str):
    if level not in ("info", "debug"):
        return
    print(f"âœ… {msg}")


def log_warn(msg: str, level: str):
    if level not in ("info", "debug"):
        return
    print(f"âš ï¸  {msg}")


def log_done(msg: str, tstart: float, level: str):
    if level not in ("info", "debug"):
        return
    w = min(_term_width(), 80)
    print(f"ğŸ {msg}ï¼ˆçµŒé {time.time() - tstart:.2f}sï¼‰")
    print("â•" * w)


# ========== ãƒ¡ã‚¤ãƒ³æ±‚è§£ãƒ«ãƒ¼ãƒãƒ³ï¼ˆé–¢æ•°ã®ã¿ï¼‰ =====================================


def scflp_solve(
    data: Dict[str, object],
    max_rounds: int = 200,
    tol: float = 1e-8,
    pulp_solver: str = "CBC",
    log_level: str = "info",
) -> Dict[str, object]:
    """
    DCG ä¸»ãƒ«ãƒ¼ãƒ—ï¼ˆouter cutting planeï¼‰:
      1) master MILPï¼ˆÎ¸æœ€å¤§åŒ–, Î£x=pï¼‰ã‚’è§£ã
      2) è¿‘ä¼¼åˆ†é›¢ã§ yÌ‚ ã‚’æ§‹æˆï¼ˆÎ²é™é †ã«rå€‹ï¼‰
      3) çœŸã® L(xÌ‚,yÌ‚) ã‚’è¨ˆç®—ã€‚é•åãŒã‚ã‚Œã° Bulge ã‚«ãƒƒãƒˆï¼ˆï¼‹æ•´æ•°ãªã‚‰ Submodularï¼‰
      4) é•åãªã—ã§åœæ­¢
    """
    J = int(data["J"])
    I = int(data["I"])
    p = int(data["p"])
    r = int(data["r"])

    # æº–å‚™
    model, xvars, theta, solver = build_master_pulp(J, p, solver_name=pulp_solver)
    cuts_added = 0
    cuts_log: List[Tuple[str, float]] = []
    t0 = time.time()

    bulge_count = 0
    submod_count = 0

    log_header("S-CFLP ã‚’è§£ãã¾ã™ï¼ˆDCG + Bulge/Submodular ã‚«ãƒƒãƒˆï¼‰", log_level)
    log_step(f"å€™è£œåœ° J = {J}, éœ€è¦ç‚¹ I = {I}, p = {p}, r = {r}", log_level)

    for it in range(1, max_rounds + 1):
        it_start = time.time()
        status = solve_master(model, solver)
        x_hat, theta_hat = get_values_pulp(xvars, theta)
        is_int = bool(np.all((x_hat < 1e-6) | (x_hat > 1 - 1e-6)))

        log_line(log_level)
        log_step(
            f"ğŸ§® ãƒ©ã‚¦ãƒ³ãƒ‰ {it}: master è§£ â†’ Î¸Ì‚ = {theta_hat:.6f}, |x| = {x_hat.sum():.0f}/{p}ï¼ˆ{'æ•´æ•°' if is_int else 'å°æ•°æ··åœ¨'}ï¼‰",
            log_level,
        )

        # è¿‘ä¼¼åˆ†é›¢
        y_hat, ub_lin, beta = approximate_separation_y(data, x_hat)
        y_idx = np.where(y_hat > 0.5)[0].tolist()
        true_val = L_value(data, x_hat, y_hat)
        gap = theta_hat - true_val
        log_step(
            f"ğŸ” åˆ†é›¢ï¼šyÌ‚ ã¯ {y_idx}ï¼ˆr = {r}ï¼‰ã€‚ä¸Šç•Œ Î± âˆ’ Î²áµ€yÌ‚ = {ub_lin:.6f}", log_level
        )
        topk = np.argsort(-beta)[: min(5, J)]
        log_debug(
            "Î² ä¸Šä½: " + ", ".join([f"j={int(j)}: Î²={beta[j]:.4g}" for j in topk]),
            log_level,
        )
        log_step(
            f"ğŸ“ è©•ä¾¡ï¼šL(xÌ‚,yÌ‚) = {true_val:.6f} â†’ é•åé‡ Î¸Ì‚ - L = {gap:.3e}", log_level
        )

        if theta_hat > true_val + tol:
            # é•åã‚ã‚Š â†’ ã‚«ãƒƒãƒˆè¿½åŠ 
            kinds = []

            # Bulge cut
            Lb, grad = Lb_and_grad(data, x_hat, y_hat)
            c0 = Lb - float((grad * x_hat).sum())
            coeffs = {j: float(grad[j]) for j in range(J) if abs(grad[j]) > 1e-12}
            node["cuts"].append((c0, coeffs))
            total_new_cuts += 1
            bulge_added += 1
            kinds.append("bulge")

            # Submodular cutï¼ˆåˆ†æ•° x ã«å¯¾ã™ã‚‹å³å¯†åˆ†é›¢ï¼‰
            c0s, coeffs_s, rhs_star, S_idx = submodular_cut_coeffs_fractional_exact(
                data, x_hat, y_hat
            )
            node["cuts"].append((c0s, coeffs_s))
            total_new_cuts += 1
            submod_added += 1
            kinds.append("submod")

            log_cut(kinds, log_level)
            log_debug(
                f"   Â· NWåˆ†é›¢: min_S H(S) = {rhs_star:.6f}ï¼ˆ|S*|={len(S_idx)}ï¼‰",
                log_level,
            )

            # Submodular cutï¼ˆåˆ†æ•° x ã«å¯¾ã—ã¦å³å¯†åˆ†é›¢ï¼‰
            c0s, coeffs_s, rhs_star, S_idx = submodular_cut_coeffs_fractional_exact(
                data, x_hat, y_hat
            )
            add_linear_cut_theta_le(
                model, theta, c0s, coeffs_s, name=f"submod_{cuts_added}"
            )
            cuts_added += 1
            submod_count += 1
            cuts_log.append(("submod", c0s))
            kinds.append("submod")

            log_cut(kinds, log_level)
            log_debug(
                f"   Â· NWåˆ†é›¢: min_S H(S) = {rhs_star:.6f}ï¼ˆ|S*|={len(S_idx)}ï¼‰",
                log_level,
            )
            log_debug(
                f"ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰æ‰€è¦: {time.time()-it_start:.2f}s / ç´¯è¨ˆã‚«ãƒƒãƒˆ {cuts_added}",
                log_level,
            )
            continue
        else:
            log_success("é•åãªã—ã€‚ç¾åœ¨ã® Y-closure ã«å¯¾ã—ã¦æœ€é©ã§ã™ã€‚", log_level)
            break

    # æœ€çµ‚åŒ–
    status = solve_master(model, solver)
    x_hat, theta_hat = get_values_pulp(xvars, theta)
    sel = np.where(x_hat > 0.5)[0].tolist()
    log_done("æ±‚è§£å®Œäº†", t0, log_level)
    log_step(f"âœ¨ ç›®çš„å€¤ Î¸ = {theta_hat:.6f} / é¸æŠã‚µã‚¤ãƒˆ {sel}", log_level)
    log_step(f"ğŸ§· è¿½åŠ ã‚«ãƒƒãƒˆ {cuts_added} æœ¬", log_level)
    log_step(
        f"ğŸ§· è¿½åŠ ã‚«ãƒƒãƒˆ åˆè¨ˆ {cuts_added} æœ¬ï¼ˆBulge: {bulge_count}, Submodular: {submod_count}ï¼‰",
        log_level,
    )
    if abs(x_hat.sum() - p) > 1e-6:
        log_warn("Î£x ãŒ p ã¨ä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚äºˆç®—åˆ¶ç´„ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚", log_level)

    return dict(
        x=x_hat,
        theta=theta_hat,
        obj=theta_hat,
        status=status,
        iterations=it,
        cuts=cuts_added,
        cuts_log=cuts_log,
        bulge_cuts=bulge_count,
        submod_cuts=submod_count,
        selected_sites=sel,
        time_sec=time.time() - t0,
    )


# ========== åˆ†æä»˜ã Branch-and-Cutï¼šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ============================


def build_master_with_fixings_and_cuts(
    nJ: int,
    p: int,
    fix1: Set[int],
    fix0: Set[int],
    cuts: List[Tuple[float, Dict[int, float]]],
    solver_name: str = "CBC",
):
    """
    åˆ†æã§ã®å›ºå®šã¨æ—¢å­˜ã‚«ãƒƒãƒˆã‚’å«ã‚ã¦ master ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚

    å¼•æ•°:
        nJ (int): æ–½è¨­å€™è£œæ•° J
        p (int): äºˆç®—
        fix1 (Set[int]): x_j=1 ã«å›ºå®šã™ã‚‹æ·»å­—é›†åˆ
        fix0 (Set[int]): x_j=0 ã«å›ºå®šã™ã‚‹æ·»å­—é›†åˆ
        cuts (List[Tuple[c0, coeffs]]): æ—¢ã«è¿½åŠ æ¸ˆã¿ã®ã‚«ãƒƒãƒˆï¼ˆÎ¸ <= c0 + Î£ coeffs_j x_jï¼‰
        solver_name (str): 'CBC' ã¾ãŸã¯ 'GLPK'

    è¿”ã‚Šå€¤:
        (model, xvars, theta, solver): PuLP ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç¾¤
    """
    import pulp

    model = pulp.LpProblem("S_CFLP_Master", pulp.LpMaximize)
    xvars = {}
    for j in range(nJ):
        if j in fix1:
            xvars[j] = pulp.LpVariable(f"x[{j}]", lowBound=1, upBound=1, cat="Binary")
        elif j in fix0:
            xvars[j] = pulp.LpVariable(f"x[{j}]", lowBound=0, upBound=0, cat="Binary")
        else:
            xvars[j] = pulp.LpVariable(f"x[{j}]", lowBound=0, upBound=1, cat="Binary")

    theta = pulp.LpVariable("theta", lowBound=0.0, upBound=1.0, cat="Continuous")
    model += pulp.lpSum([xvars[j] for j in range(nJ)]) == p, "budget_eq"
    model += theta, "obj"

    # æ—¢å­˜ã‚«ãƒƒãƒˆã‚’å†è¿½åŠ 
    for k, (c0, coeffs) in enumerate(cuts):
        expr = 0.0
        for j, cj in coeffs.items():
            expr += cj * xvars[j]
        model += (theta - expr <= c0), f"cut_replay_{k}"

    if solver_name == "CBC":
        solver = pulp.PULP_CBC_CMD(msg=False)
    elif solver_name == "GLPK":
        solver = pulp.GLPK_CMD(msg=False)
    else:
        solver = pulp.PULP_CBC_CMD(msg=False)

    return model, xvars, theta, solver


def choose_branch_variable(x_hat: np.ndarray) -> Optional[int]:
    """
    åˆ†æã§å›ºå®šã™ã‚‹å¤‰æ•° j* ã‚’é¸ã¶ï¼ˆ0.5 ã«æœ€ã‚‚è¿‘ã„å°æ•°å€¤ï¼‰ã€‚

    å¼•æ•°:
        x_hat (np.ndarray): (J,) ç¾åœ¨ã®è§£

    è¿”ã‚Šå€¤:
        int or None: åˆ†æå¯¾è±¡ã®æ·»å­—ã€‚ã™ã¹ã¦æ•´æ•°ãªã‚‰ Noneã€‚
    """
    frac = np.where((x_hat > 1e-6) & (x_hat < 1 - 1e-6))[0]
    if len(frac) == 0:
        return None
    j_star = int(frac[np.argmin(np.abs(x_hat[frac] - 0.5))])
    return j_star


def node_solve_until_no_violation(
    data: Dict[str, object],
    node: Dict[str, object],
    pulp_solver: str,
    tol: float,
    max_cuts_per_node: int = 200,
    log_level: str = "info",
):
    """
    1ã¤ã®ãƒãƒ¼ãƒ‰ï¼ˆéƒ¨åˆ†å•é¡Œï¼‰ã«ã¤ã„ã¦ã€ã‚«ãƒƒãƒˆè¿½åŠ ã‚’ç¹°ã‚Šè¿”ã—ã¦é•åãŒç„¡ããªã‚‹ã¾ã§è§£ãã€‚

    å¼•æ•°:
        data (dict): å•é¡Œãƒ‡ãƒ¼ã‚¿
        node (dict): {"fix1": set, "fix0": set, "cuts": list[(c0, coeffs)], "depth": int}
        pulp_solver (str): PuLP ã‚½ãƒ«ãƒå
        tol (float): åæŸåˆ¤å®šè¨±å®¹
        max_cuts_per_node (int): 1ãƒãƒ¼ãƒ‰ã§è¿½åŠ å¯èƒ½ãªã‚«ãƒƒãƒˆã®ä¸Šé™
        log_level (str): 'info' or 'debug' or 'quiet'

    è¿”ã‚Šå€¤:
        dict: {
          "status": int, "x_hat": np.ndarray, "theta_hat": float,
          "y_hat": np.ndarray, "true_val": float, "viol": float,
          "integral": bool, "cuts_added": int
        }
    """
    J = int(data["J"])
    total_new_cuts = 0
    bulge_added = 0
    submod_added = 0

    for _ in range(max_cuts_per_node):
        model, xvars, theta, solver = build_master_with_fixings_and_cuts(
            nJ=J,
            p=int(data["p"]),
            fix1=node["fix1"],
            fix0=node["fix0"],
            cuts=node["cuts"],
            solver_name=pulp_solver,
        )
        status = solve_master(model, solver)
        x_hat, theta_hat = get_values_pulp(xvars, theta)
        is_int = bool(np.all((x_hat < 1e-6) | (x_hat > 1 - 1e-6)))

        # è¿‘ä¼¼åˆ†é›¢ & çœŸã®è©•ä¾¡
        y_hat, ub_lin, beta = approximate_separation_y(data, x_hat)
        true_val = L_value(data, x_hat, y_hat)
        gap = theta_hat - true_val

        log_step(
            f"   Â· ãƒãƒ¼ãƒ‰(depth={node['depth']}): Î¸Ì‚={theta_hat:.6f}, L={true_val:.6f}, viol={gap:.3e}",
            log_level,
        )

        if theta_hat <= true_val + tol:
            # é•åãªã— â†’ åæŸ
            return dict(
                status=status,
                x_hat=x_hat,
                theta_hat=theta_hat,
                y_hat=y_hat,
                true_val=true_val,
                viol=gap,
                integral=is_int,
                cuts_added=total_new_cuts,
                bulge_added=bulge_added,
                submod_added=submod_added,
            )

        # é•åã‚ã‚Š â†’ ã‚«ãƒƒãƒˆè¿½åŠ 
        Lb, grad = Lb_and_grad(data, x_hat, y_hat)
        c0 = Lb - float((grad * x_hat).sum())
        coeffs = {j: float(grad[j]) for j in range(J) if abs(grad[j]) > 1e-12}
        node["cuts"].append((c0, coeffs))
        total_new_cuts += 1
        bulge_added += 1
        kinds = ["bulge"]

        if is_int:
            x_bin = (x_hat > 0.5).astype(float)
            y_bin = (y_hat > 0.5).astype(float)
            c0s, coeffs_s = submodular_cut_coeffs(data, x_bin, y_bin)
            node["cuts"].append((c0s, coeffs_s))
            total_new_cuts += 1
            submod_added += 1
            kinds.append("submod")

        log_cut(kinds, log_level)

        if total_new_cuts >= max_cuts_per_node:
            log_warn(
                "ã“ã®ãƒãƒ¼ãƒ‰ã§ã®ã‚«ãƒƒãƒˆä¸Šé™ã«åˆ°é”ã€‚ä¸­æ–­ã—ã¦ä¸Šä½ã§å‡¦ç†ã—ã¾ã™ã€‚", log_level
            )
            break

    # ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ãŸå ´åˆï¼ˆä¸Šé™åˆ°é”ãªã©ï¼‰
    return dict(
        status=status,
        x_hat=x_hat,
        theta_hat=theta_hat,
        y_hat=y_hat,
        true_val=true_val,
        viol=gap,
        integral=is_int,
        cuts_added=total_new_cuts,
        bulge_added=bulge_added,
        submod_added=submod_added,
    )


def make_node(
    fix1: Optional[Set[int]] = None,
    fix0: Optional[Set[int]] = None,
    cuts: Optional[List[Tuple[float, Dict[int, float]]]] = None,
    depth: int = 0,
):
    """
    åˆ†æãƒãƒ¼ãƒ‰ï¼ˆéƒ¨åˆ†å•é¡Œï¼‰ã‚’ä½œã‚‹ç°¡æ˜“ãƒ•ã‚¡ã‚¯ãƒˆãƒªã€‚

    å¼•æ•°:
        fix1 (set[int] | None): x_j=1 ã«å›ºå®šã™ã‚‹æ·»å­—é›†åˆ
        fix0 (set[int] | None): x_j=0 ã«å›ºå®šã™ã‚‹æ·»å­—é›†åˆ
        cuts (list | None): æ—¢å­˜ã‚«ãƒƒãƒˆï¼ˆ(c0, coeffs) ã®ãƒªã‚¹ãƒˆï¼‰
        depth (int): æ¢ç´¢æœ¨ã®æ·±ã•

    è¿”ã‚Šå€¤:
        dict: {"fix1", "fix0", "cuts", "depth", "ub"}
    """
    return dict(
        fix1=set() if fix1 is None else set(fix1),
        fix0=set() if fix0 is None else set(fix0),
        cuts=[] if cuts is None else list(cuts),
        depth=int(depth),
        ub=float("inf"),  # ä¸Šç•Œï¼ˆç›´è¿‘ Î¸Ì‚ï¼‰
    )


# ========== ãƒ¡ã‚¤ãƒ³ï¼šå®Œå…¨ Branch-and-Cutï¼ˆåˆ†æå«ã‚€ï¼‰ =============================


def scflp_branch_and_cut(
    data: Dict[str, object],
    max_nodes: int = 10_000,
    max_rounds_per_node: int = 200,
    tol: float = 1e-8,
    pulp_solver: str = "CBC",
    node_selection: str = "dfs",  # 'dfs' or 'bestbound'
    log_level: str = "info",
) -> Dict[str, object]:
    """
    S-CFLP ã®å®Œå…¨ Branch-and-Cutï¼ˆåˆ†æ + ã‚«ãƒƒãƒˆç”Ÿæˆï¼‰ã‚’è§£ãã€‚

    ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆAlgorithm 1 ã«å¯¾å¿œï¼‰:
        1) ãƒ«ãƒ¼ãƒˆãƒãƒ¼ãƒ‰ã«ç·©å’Œå•é¡Œã‚’å…¥ã‚Œã¦åˆæœŸåŒ–
        2) ãƒãƒ¼ãƒ‰ã‚’å–ã‚Šå‡ºã™ï¼ˆDFS æ—¢å®šï¼‰
        3) ãƒãƒ¼ãƒ‰å†…ã§ cutting-plane ã‚’åæŸã•ã›ã‚‹ï¼ˆé•åãŒãªããªã‚‹ã¾ã§ï¼‰
        4) Î¸Ì‚ <= Î¸_LB ãªã‚‰æåˆˆã‚Š
           4-1) x ãŒæ•´æ•°ãªã‚‰ã‚¤ãƒ³ã‚«ãƒ³ãƒ™ãƒ³ãƒˆæ›´æ–°
           4-2) x ãŒå°æ•°ãªã‚‰æœ€ã‚‚ 0.5 ã«è¿‘ã„ x_j ã§åˆ†æã—ã¦ 2 å­ãƒãƒ¼ãƒ‰ç”Ÿæˆ
        5) ãƒãƒ¼ãƒ‰é›†åˆãŒç©ºã«ãªã‚‹ã¾ã§ç¹°ã‚Šè¿”ã™

    å¼•æ•°:
        data (dict): å•é¡Œãƒ‡ãƒ¼ã‚¿è¾æ›¸
        max_nodes (int): ãƒãƒ¼ãƒ‰æ¢ç´¢ç·æ•°ã®ä¸Šé™
        max_rounds_per_node (int): 1ãƒãƒ¼ãƒ‰å†…ã®ã‚«ãƒƒãƒˆåå¾©ä¸Šé™
        tol (float): åæŸåˆ¤å®šç”¨ã®è¨±å®¹
        pulp_solver (str): PuLP ã‚½ãƒ«ãƒãƒ¼åï¼ˆCBC/GLPKï¼‰
        node_selection (str): 'dfs'ï¼ˆstackï¼‰ã¾ãŸã¯ 'bestbound'ï¼ˆæœ€å¤§ä¸Šç•Œé¸æŠï¼‰
        log_level (str): 'info' / 'debug' / 'quiet'

    è¿”ã‚Šå€¤:
        dict: {
          "x_best": np.ndarray or None,
          "theta_best": float,
          "status": str,
          "nodes_explored": int,
          "time_sec": float,
          "gap_bound": float  # (ä¸Šç•Œ-ä¸‹ç•Œ)
        }
    """
    J = int(data["J"])
    p = int(data["p"])
    t0 = time.time()

    # ä¸‹ç•Œãƒ»ãƒ™ã‚¹ãƒˆè§£
    theta_LB = 0.0
    x_best = None

    total_bulge = 0
    total_submod = 0
    total_cuts = 0

    # ãƒ«ãƒ¼ãƒˆãƒãƒ¼ãƒ‰
    root = make_node()
    if p < 0 or p > J:
        return dict(
            x_best=None,
            theta_best=theta_LB,
            status="infeasible",
            nodes_explored=0,
            time_sec=0.0,
            gap_bound=float("inf"),
        )

    # ãƒãƒ¼ãƒ‰é›†åˆ
    nodes: List[Dict[str, object]] = [root]

    explored = 0
    log_header("Branch-and-Cutï¼ˆåˆ†æï¼‹ã‚«ãƒƒãƒˆï¼‰é–‹å§‹", log_level)

    while nodes and explored < max_nodes:
        # ãƒãƒ¼ãƒ‰å–ã‚Šå‡ºã—
        if node_selection == "bestbound":
            # ub ãŒæœ€å¤§ã®ã‚‚ã®
            idx = int(np.argmax([n.get("ub", -1e100) for n in nodes]))
            node = nodes.pop(idx)
        else:
            # DFS
            node = nodes.pop()

        explored += 1
        log_line(log_level)
        log_step(
            f"ğŸŒ¿ ãƒãƒ¼ãƒ‰å±•é–‹: depth={node['depth']}, |fix1|={len(node['fix1'])}, |fix0|={len(node['fix0'])}",
            log_level,
        )

        # äºˆç®—ã®æ—©æœŸãƒã‚§ãƒƒã‚¯ï¼šã™ã§ã« x=1 å›ºå®šãŒ p è¶…ãˆãªã‚‰ infeasible
        if len(node["fix1"]) > p:
            log_warn("æ—©æœŸæåˆˆã‚Š: |fix1| > p", log_level)
            continue

        # ãƒãƒ¼ãƒ‰å†…ã§ cutting-plane ã‚’åæŸã•ã›ã‚‹
        info = node_solve_until_no_violation(
            data=data,
            node=node,
            pulp_solver=pulp_solver,
            tol=tol,
            max_cuts_per_node=max_rounds_per_node,
            log_level=log_level,
        )
        theta_hat = info["theta_hat"]
        x_hat = info["x_hat"]
        is_int = info["integral"]
        node["ub"] = float(theta_hat)

        total_cuts += int(info.get("cuts_added", 0))
        total_bulge += int(info.get("bulge_added", 0))
        total_submod += int(info.get("submod_added", 0))

        # ä¸Šç•Œã«ã‚ˆã‚‹æåˆˆã‚Š
        if theta_hat <= theta_LB + tol:
            log_step(f"ğŸª“ æåˆˆã‚Š: Î¸Ì‚={theta_hat:.6f} <= Î¸_LB={theta_LB:.6f}", log_level)
            continue

        # æ•´æ•°è§£ãªã‚‰ã‚¤ãƒ³ã‚«ãƒ³ãƒ™ãƒ³ãƒˆæ›´æ–°
        if is_int:
            x_bin = (x_hat > 0.5).astype(float)
            theta_LB = float(theta_hat)
            x_best = x_bin
            log_success(f"ğŸ¯ ã‚¤ãƒ³ã‚«ãƒ³ãƒ™ãƒ³ãƒˆæ›´æ–°: Î¸_LB â† {theta_LB:.6f}", log_level)
            continue

        # åˆ†æï¼ˆæœ€ã‚‚ 0.5 ã«è¿‘ã„å¤‰æ•°ï¼‰
        j_star = choose_branch_variable(x_hat)
        if j_star is None:
            # å°æ•°åˆ¤å®šã«æ¥ãªã„ã¯ãšã ãŒä¿é™º
            x_bin = (x_hat > 0.5).astype(float)
            theta_LB = max(theta_LB, float(theta_hat))
            x_best = x_bin
            log_warn("x ã¯å®Ÿè³ªæ•´æ•°ã ã£ãŸãŸã‚æ›´æ–°ã®ã¿ã€‚", log_level)
            continue

        print("åˆ†å²ã™ã‚‹ã")
        # å­ãƒãƒ¼ãƒ‰ 2 å€‹ï¼ˆx_j=0, x_j=1ï¼‰
        child0 = make_node(
            fix1=node["fix1"],
            fix0=node["fix0"] | {j_star},
            cuts=node["cuts"],
            depth=node["depth"] + 1,
        )

        child1 = make_node(
            fix1=node["fix1"] | {j_star},
            fix0=node["fix0"],
            cuts=node["cuts"],
            depth=node["depth"] + 1,
        )

        # æ—©æœŸä¸å¯èƒ½æ€§: child1 ã®å›ºå®šãŒ p ã‚’è¶…ãˆãŸã‚‰æ¨ã¦ã‚‹
        if len(child1["fix1"]) > p:
            log_warn(f"å­ãƒãƒ¼ãƒ‰(x[{j_star}]=1)ã¯ |fix1|>p ã®ãŸã‚ç ´æ£„", log_level)
        else:
            nodes.append(child1)

        # child0 ã¯ x_j=0 ãªã®ã§å¸¸ã«å¯
        nodes.append(child0)
        log_step(
            f"ğŸŒ± åˆ†æ: j*={j_star} â†’ å­ãƒãƒ¼ãƒ‰ depth={node['depth']+1} ã‚’2ã¤è¿½åŠ ",
            log_level,
        )

    # çµ‚äº†
    elapsed = time.time() - t0
    gap = (
        (max([n.get("ub", 0.0) for n in nodes], default=theta_LB) - theta_LB)
        if nodes
        else 0.0
    )
    status = "optimal" if not nodes else "stopped_or_pruned"

    log_done("Branch-and-Cut çµ‚äº†", t0, log_level)
    if x_best is not None:
        sel = np.where(x_best > 0.5)[0].tolist()
        log_step(f"âœ¨ æœ€è‰¯è§£ Î¸ = {theta_LB:.6f} / é¸æŠã‚µã‚¤ãƒˆ {sel}", log_level)
    else:
        log_warn("å®Ÿè¡Œä¸­ã«ã‚¤ãƒ³ã‚«ãƒ³ãƒ™ãƒ³ãƒˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚", log_level)

    log_step(
        f"ğŸ§¾ ã‚«ãƒƒãƒˆç·è¨ˆ: {total_cuts} æœ¬ï¼ˆBulge: {total_bulge}, Submodular: {total_submod}ï¼‰",
        log_level,
    )

    return dict(
        x_best=x_best,
        theta_best=float(theta_LB),
        status=status,
        nodes_explored=explored,
        time_sec=elapsed,
        gap_bound=float(gap),
        total_cuts=total_cuts,
        total_bulge=total_bulge,
        total_submod=total_submod,
    )


# ========= å³å¯†åˆ†é›¢ï¼šåˆ†æ•° x ç”¨ Submodular (NW) ã‚«ãƒƒãƒˆ =========


def _Ly_S_and_union_allk(
    data: Dict[str, object], S_bin: np.ndarray, y_bin: np.ndarray
) -> Tuple[float, np.ndarray]:
    """
    L_Y(S) ã¨ã€å…¨ã¦ã® k ã«ã¤ã„ã¦ L_Y(S âˆª {k}) ã‚’åŒæ™‚ã«è¿”ã™ã€‚
    ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ã‚ˆã‚Š O(IJ) ã§è¨ˆç®—ï¼ˆk ã”ã¨ã«å†è©•ä¾¡ã—ãªã„ï¼‰ã€‚
    """
    w = data["w"]  # (I,J)
    UL = data["UL"]  # (I,)
    UF = data["UF"]  # (I,)
    h = data["h"]  # (I,)
    S_bin = S_bin.reshape(-1)
    y_bin = y_bin.reshape(-1)
    I, J = w.shape

    wS = w.dot(S_bin)  # (I,)
    wSY = w.dot(np.maximum(S_bin, y_bin))  # (I,)

    num_S = UL + wS
    den_S = UL + UF + wSY
    Ly_S = float((h * (num_S / den_S)).sum())  # scalar

    add_S = 1.0 - S_bin  # (J,)
    add_SY = 1.0 - np.maximum(S_bin, y_bin)  # (J,)

    # ã™ã¹ã¦ã® k ã«ã¤ã„ã¦ Sâˆª{k} ã®è©•ä¾¡ã‚’ä¸€æ‹¬ã§ä½œã‚‹
    num_all = num_S[:, None] + w * add_S[None, :]  # (I,J)
    den_all = den_S[:, None] + w * add_SY[None, :]  # (I,J)
    Ly_SuK = (h[:, None] * (num_all / den_all)).sum(axis=0)  # (J,)

    return Ly_S, Ly_SuK


def _rho_full_minus_k_vector(
    data: Dict[str, object], y_bin: np.ndarray
) -> Tuple[float, np.ndarray]:
    """
    Ï_Y(J\{k};k) ã‚’å…¨ k ã«ã¤ã„ã¦åŒæ™‚ã«è¿”ã™ã€‚
    ä½µã›ã¦ L_Y(J) ã‚‚è¿”ã™ã€‚
    """
    w = data["w"]  # (I,J)
    UL = data["UL"]  # (I,)
    UF = data["UF"]  # (I,)
    h = data["h"]  # (I,)
    y_bin = y_bin.reshape(-1)
    I, J = w.shape

    onesJ = np.ones(J)
    wJ = w.dot(onesJ)  # (I,)
    num_J = UL + wJ
    den_J = UL + UF + wJ
    Ly_J = float((h * (num_J / den_J)).sum())

    # J\{k} âˆª Y ã®ç·å’Œã¯ã€y_k=1 ã®ã¨ã Jã€y_k=0 ã®ã¨ã J\{k}
    y_bar = 1.0 - y_bin  # (J,)

    num_J_minus_k = UL[:, None] + wJ[:, None] - w  # (I,J)
    den_J_minus_k = UL[:, None] + UF[:, None] + wJ[:, None] - (y_bar[None, :] * w)
    Ly_J_minus_k = (h[:, None] * (num_J_minus_k / den_J_minus_k)).sum(axis=0)  # (J,)

    rho_full = Ly_J - Ly_J_minus_k  # (J,)
    return Ly_J, rho_full


def _H_value(
    data: Dict[str, object],
    x: np.ndarray,
    y_bin: np.ndarray,
    S_bin: np.ndarray,
    pre: Dict[str, object],
) -> float:
    """
    H(S) = L_Y(S) - sum_{kâˆˆS} Ï_full(k)*(1-x_k) + sum_k x_k * L_Y(Sâˆª{k}) - p*L_Y(S)
    ã‚’è¿”ã™ã€‚pre ã«ã¯ Ly_J, rho_full, H_empty, p ã‚’æŒãŸã›ã‚‹ã€‚
    """
    Ly_S, Ly_SuK = _Ly_S_and_union_allk(data, S_bin, y_bin)
    p = pre["p"]
    rho_full = pre["rho_full"]
    term1 = Ly_S
    term2 = -float(((rho_full * (1.0 - x)) * S_bin).sum())  # kâˆˆS ã®å’Œ
    term3 = float(x.dot(Ly_SuK)) - p * Ly_S
    return term1 + term2 + term3


def _H_empty(data: Dict[str, object], x: np.ndarray, y_bin: np.ndarray) -> float:
    """H(âˆ…) ã‚’è¿”ã™ï¼ˆæ­£è¦åŒ–ç”¨ï¼‰ã€‚"""
    J = int(data["J"])
    S0 = np.zeros(J)
    Ly_0, Ly_0_u_k = _Ly_S_and_union_allk(data, S0, y_bin)
    p = int(data["p"])
    # H(âˆ…) = L_Y(âˆ…) + sum_k x_k L_Y({k}) - p*L_Y(âˆ…)
    return float(Ly_0 + x.dot(Ly_0_u_k) - p * Ly_0)


def _greedy_extreme_point_for_baseF(
    data: Dict[str, object],
    x: np.ndarray,
    y_bin: np.ndarray,
    weights: np.ndarray,
    pre: Dict[str, object],
) -> np.ndarray:
    """
    Base polyhedron B(F) ã®æ¥µç‚¹ã‚’ã€Œè²ªæ¬²æ³•ã€ã§è¿”ã™ã€‚
    ã“ã“ã§ F(S) = H(S) - H(âˆ…)ã€‚ã‚ˆã£ã¦ F(âˆ…)=0ã€‚
    """
    J = int(data["J"])
    order = np.argsort(weights)  # æ˜‡é †ï¼ˆæœ€å°åŒ–ï¼‰
    S_bin = np.zeros(J)
    v = np.zeros(J)
    F_prev = 0.0

    for idx in order:
        S_bin[idx] = 1.0
        H_curr = _H_value(data, x, y_bin, S_bin, pre)
        F_curr = H_curr - pre["H_empty"]
        v[idx] = F_curr - F_prev
        F_prev = F_curr

    # æ•°å€¤èª¤å·®ã®å¾®èª¿æ•´
    s = v.sum()
    FJ = _H_value(data, x, y_bin, np.ones(J), pre) - pre["H_empty"]
    if abs(s - FJ) > 1e-9:
        v[order[-1]] += FJ - s
    return v


def _mnp_min_norm_point(
    data: Dict[str, object],
    x: np.ndarray,
    y_bin: np.ndarray,
    pre: Dict[str, object],
    max_iter: int = 60,
    eps: float = 1e-8,
) -> np.ndarray:
    """
    Fujishigeâ€“Wolfe ã® Minimum-Norm-Point ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç°¡æ˜“ Active-Set ç‰ˆï¼‰ã€‚
    è¿”ã‚Šå€¤ã¯ B(F) ä¸Šã®æœ€å°ãƒãƒ«ãƒ ç‚¹ yã€‚æœ€å°åŒ–è§£é›†åˆã¯ {i : y_i < 0} ãŒä¸€ã¤ã®ä»£è¡¨ã€‚
    """
    J = int(data["J"])
    rng = np.random.default_rng(0)
    w0 = rng.normal(size=J)  # åˆæœŸé‡ã¿ï¼ˆä»»æ„ã§OKï¼‰
    v0 = _greedy_extreme_point_for_baseF(data, x, y_bin, w0, pre)

    V = [v0]  # æ¥µç‚¹ã®ãƒªã‚¹ãƒˆï¼ˆå„ã¯ R^J ãƒ™ã‚¯ãƒˆãƒ«ï¼‰
    lamb = np.array([1.0])  # å‡¸çµåˆä¿‚æ•°
    y = v0.copy()

    for _ in range(max_iter):
        v = _greedy_extreme_point_for_baseF(data, x, y_bin, y, pre)
        # optimality test: y Â· (y - v) <= eps
        if float(y.dot(y - v)) <= eps:
            return y

        # è¿½åŠ ã—ã¦å°„å½±ï¼ˆWolfe ã® minor loopï¼‰
        V.append(v)
        m = len(V)
        Vmat = np.column_stack(V)  # (J, m)

        # minor ãƒ«ãƒ¼ãƒ—
        # ç›®çš„ï¼šmin ||Vmat * alpha||^2 s.t. sum alpha = 1, alpha >= 0
        alpha = np.zeros(m)
        alpha[:-1] = lamb
        alpha[-1] = 0.0

        while True:
            G = Vmat.T @ Vmat  # (m,m)
            ones = np.ones(m)
            # KKT: [G 1; 1^T 0] [lambda; mu] = [0; 1]
            KKT = np.block([[G, ones[:, None]], [ones[None, :], np.zeros((1, 1))]])
            rhs = np.zeros(m + 1)
            rhs[-1] = 1.0
            sol = np.linalg.lstsq(KKT, rhs, rcond=None)[0]
            lam_new = sol[:m]  # ç¬¦å·åˆ¶ç´„ãªã—ã®å°„å½±è§£
            # ã‚‚ã—å…¨æˆåˆ† >= 0 ãªã‚‰ã€ãã‚ŒãŒå‡¸çµåˆä¿‚æ•°
            if np.all(lam_new >= -1e-12):
                lamb = lam_new
                y = Vmat @ lamb
                break
            # è² ã®æˆåˆ†ãŒã‚ã‚‹ â†’ ãã®æ–¹å‘ã«æ²¿ã£ã¦ 0 ã¾ã§å‹•ã‹ã—ã¦ç‚¹ã‚’é–“å¼•ã
            dirv = lam_new - alpha
            bad = dirv < 0
            t = np.min(alpha[bad] / (alpha[bad] - lam_new[bad]))
            alpha = alpha + t * (lam_new - alpha)
            keep = alpha > 1e-12
            V = [V[i] for i in range(m) if keep[i]]
            alpha = alpha[keep]
            Vmat = np.column_stack(V)
            m = len(V)
            # ç¶­æŒ
            lamb = alpha / alpha.sum()
            y = Vmat @ lamb

    return y  # ä¸Šé™åå¾©åˆ°é”ï¼ˆé€šå¸¸ã¯åæŸå‰ã«è¿”ã‚‹ï¼‰


def submodular_cut_coeffs_fractional_exact(
    data: Dict[str, object],
    x: np.ndarray,
    y_hat: np.ndarray,
) -> Tuple[float, Dict[int, float], float, np.ndarray]:
    """
    åˆ†æ•° x ã«å¯¾ã™ã‚‹å³å¯† NW ã‚«ãƒƒãƒˆï¼ˆå¼(8)ï¼‰ã‚’è¿”ã™ã€‚
    è¿”ã‚Šå€¤: (c0, coeffs, rhs_value, S_star_indices)
    """
    J = int(data["J"])
    x = x.reshape(J)
    y_bin = (y_hat > 0.5).astype(float).reshape(J)

    # äº‹å‰è¨ˆç®—ï¼ˆÏ_full ã¨ H(âˆ…)ï¼‰
    Ly_J, rho_full = _rho_full_minus_k_vector(data, y_bin)
    H0 = _H_empty(data, x, y_bin)
    pre = dict(Ly_J=Ly_J, rho_full=rho_full, H_empty=H0, p=int(data["p"]))

    # MNP ã§ H(S) ã‚’æœ€å°åŒ–ï¼ˆF(S)=H(S)-H(âˆ…) ã®åŸºåº•å¤šé¢ä½“ä¸Šã®æœ€å°ãƒãƒ«ãƒ ç‚¹ï¼‰
    y_mnp = _mnp_min_norm_point(data, x, y_bin, pre)
    S_star = (y_mnp < 0.0 - 1e-12).astype(float)  # ä¸€ã¤ã®æœ€å°åŒ–è§£
    S_idx = np.where(S_star > 0.5)[0]

    # ä¿‚æ•°çµ„ã¿ç«‹ã¦ï¼ˆå¼(8)ï¼‰ï¼šc0 ã¨ c_j
    Ly_S, Ly_SuK = _Ly_S_and_union_allk(data, S_star, y_bin)
    coeffs: Dict[int, float] = {}

    # k âˆˆ S: coeff = Ï_Y(J\{k};k)
    for k in S_idx:
        coeffs[int(k)] = float(rho_full[k])

    # k âˆ‰ S: coeff = Ï_Y(S;k) = L_Y(Sâˆª{k}) - L_Y(S)
    notS = np.where(S_star < 0.5)[0]
    rho_S_k = Ly_SuK[notS] - Ly_S
    for k, val in zip(notS, rho_S_k):
        coeffs[int(k)] = float(val)

    c0 = float(Ly_S - rho_full[S_idx].sum())

    # å‚è€ƒï¼šå¼(9)å³è¾ºï¼ˆæœ€å°å€¤ï¼‰= c0 + Î£ c_j x_j
    rhs_val = c0 + float(sum(coeffs[j] * x[j] for j in range(J)))

    return c0, coeffs, rhs_val, S_idx
